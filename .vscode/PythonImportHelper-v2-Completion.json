[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "CNN_2d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "CNN_2d",
        "description": "CNN_2d",
        "detail": "CNN_2d",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "load_dataset_mask",
        "importPath": "data_loader",
        "description": "data_loader",
        "isExtraImport": true,
        "detail": "data_loader",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_planner",
        "importPath": "data_loader",
        "description": "data_loader",
        "isExtraImport": true,
        "detail": "data_loader",
        "documentation": {}
    },
    {
        "label": "load_dataset_crossentropy",
        "importPath": "data_loader",
        "description": "data_loader",
        "isExtraImport": true,
        "detail": "data_loader",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_crossentropy",
        "importPath": "data_loader",
        "description": "data_loader",
        "isExtraImport": true,
        "detail": "data_loader",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "obstacle_handling_3d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "obstacle_handling_3d",
        "description": "obstacle_handling_3d",
        "detail": "obstacle_handling_3d",
        "documentation": {}
    },
    {
        "label": "Poly3DCollection",
        "importPath": "mpl_toolkits.mplot3d.art3d",
        "description": "mpl_toolkits.mplot3d.art3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d.art3d",
        "documentation": {}
    },
    {
        "label": "Poly3DCollection",
        "importPath": "mpl_toolkits.mplot3d.art3d",
        "description": "mpl_toolkits.mplot3d.art3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d.art3d",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "obstacle_handling",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "obstacle_handling",
        "description": "obstacle_handling",
        "detail": "obstacle_handling",
        "documentation": {}
    },
    {
        "label": "torchvision.models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.models",
        "description": "torchvision.models",
        "detail": "torchvision.models",
        "documentation": {}
    },
    {
        "label": "pack_padded_sequence",
        "importPath": "torch.nn.utils.rnn",
        "description": "torch.nn.utils.rnn",
        "isExtraImport": true,
        "detail": "torch.nn.utils.rnn",
        "documentation": {}
    },
    {
        "label": "pack_padded_sequence",
        "importPath": "torch.nn.utils.rnn",
        "description": "torch.nn.utils.rnn",
        "isExtraImport": true,
        "detail": "torch.nn.utils.rnn",
        "documentation": {}
    },
    {
        "label": "pack_padded_sequence",
        "importPath": "torch.nn.utils.rnn",
        "description": "torch.nn.utils.rnn",
        "isExtraImport": true,
        "detail": "torch.nn.utils.rnn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "Axes3D",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "Axes3D",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "ipywidgets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "interact",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "IntSlider",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "SimpleITK",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "SimpleITK",
        "description": "SimpleITK",
        "detail": "SimpleITK",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "polygon",
        "importPath": "skimage.draw",
        "description": "skimage.draw",
        "isExtraImport": true,
        "detail": "skimage.draw",
        "documentation": {}
    },
    {
        "label": "MLP_3D",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "MLP_original",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "MLP_3D",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "MLP",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "AE_R_3d_CNN.CNN_3d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "AE_R_3d_CNN.CNN_3d",
        "description": "AE_R_3d_CNN.CNN_3d",
        "detail": "AE_R_3d_CNN.CNN_3d",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "load_dataset_crossentropy",
        "importPath": "data_loader_crossentropy_concave_2d",
        "description": "data_loader_crossentropy_concave_2d",
        "isExtraImport": true,
        "detail": "data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_crossentropy",
        "importPath": "data_loader_crossentropy_concave_2d",
        "description": "data_loader_crossentropy_concave_2d",
        "isExtraImport": true,
        "detail": "data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "AE_concave_2d_CNN.CNN_2d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "AE_concave_2d_CNN.CNN_2d",
        "description": "AE_concave_2d_CNN.CNN_2d",
        "detail": "AE_concave_2d_CNN.CNN_2d",
        "documentation": {}
    },
    {
        "label": "load_dataset_crossentropy",
        "importPath": "data_loader_crossentropy_R_3d",
        "description": "data_loader_crossentropy_R_3d",
        "isExtraImport": true,
        "detail": "data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_crossentropy",
        "importPath": "data_loader_crossentropy_R_3d",
        "description": "data_loader_crossentropy_R_3d",
        "isExtraImport": true,
        "detail": "data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "MLP_3D",
        "importPath": "model_R_3D",
        "description": "model_R_3D",
        "isExtraImport": true,
        "detail": "model_R_3D",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ATOA.AE_concave_2d_CNN.AutoEncoder",
        "description": "ATOA.AE_concave_2d_CNN.AutoEncoder",
        "peekOfCode": "def main(args):\t\n    if not os.path.exists(args.model_path):\n        os.makedirs(args.model_path)\n    encoder=AE.Encoder_CNN_2D()\n    decoder=AE.Decoder_CNN_2D()\n    if args.preload_encoder_decoder:\n        encoder.load_state_dict(torch.load('./models/test/no_Relu/cae_encoder_cnn_2d_epoch_400_average loss_0.000636_Validation average loss_0.001110.pkl'))\n        print(\"load_the_pre-trained_encoder_model\")\n        decoder.load_state_dict(torch.load('./models/test/no_Relu/cae_decoder_cnn_2d_epoch_400_average loss_0.000636_Validation average loss_0.001110.pkl'))\n        print(\"load_the_pre-trained_decoder_model\")",
        "detail": "ATOA.AE_concave_2d_CNN.AutoEncoder",
        "documentation": {}
    },
    {
        "label": "Encoder_CNN_2D",
        "kind": 6,
        "importPath": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "description": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "peekOfCode": "class Encoder_CNN_2D(nn.Module):\n    def __init__(self,mask_size=160,dropout_p=0):\n        super(Encoder_CNN_2D, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(4), \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout(dropout_p), \n            nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1),",
        "detail": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "documentation": {}
    },
    {
        "label": "Decoder_CNN_2D",
        "kind": 6,
        "importPath": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "description": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "peekOfCode": "class Decoder_CNN_2D(nn.Module):\n    def __init__(self, dropout_p=0):\n        super(Decoder_CNN_2D, self).__init__()\n        self.fc_layers = nn.Sequential(\n            #Reverse fully connected layer\n            nn.Linear(28, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(dropout_p),\n            nn.Linear(128, 512),",
        "detail": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "documentation": {}
    },
    {
        "label": "Encoder_CNN_2D_Layernorm",
        "kind": 6,
        "importPath": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "description": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "peekOfCode": "class Encoder_CNN_2D_Layernorm(nn.Module):\n    def __init__(self,mask_size=160,dropout_p=0):\n        super(Encoder_CNN_2D_Layernorm, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n            nn.LayerNorm([4, mask_size, mask_size]),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1),\n            nn.LayerNorm([8, 80, 80]),",
        "detail": "ATOA.AE_concave_2d_CNN.CNN_2d",
        "documentation": {}
    },
    {
        "label": "load_dataset_mask",
        "kind": 2,
        "importPath": "ATOA.AE_concave_2d_CNN.data_loader",
        "description": "ATOA.AE_concave_2d_CNN.data_loader",
        "peekOfCode": "def load_dataset_mask(N=120,NP=1800):\n    # obstacles=np.zeros((N,8800),dtype=np.float32)\n    # for i in range(0,N):\n    #     temp=np.fromfile('../../../DATA_SET/obs_cloud_for_CAE/obc_complex'+str(i)+'.dat')\n    #     temp=temp.reshape(len(temp)//2,2) #change/->// due to python3 by zheng\n    #     obstacles[i]=temp.flatten()\n##########################\n    # obc=np.zeros((N,11,2),dtype=np.float32)\n    # temp=np.fromfile('../../../DATA_SET/Concave_2D/obs.dat')\n    # obs=temp.reshape(len(temp)//2,2) #change by z ",
        "detail": "ATOA.AE_concave_2d_CNN.data_loader",
        "documentation": {}
    },
    {
        "label": "length_obc",
        "kind": 5,
        "importPath": "ATOA.AE_concave_2d_CNN.data_loader",
        "description": "ATOA.AE_concave_2d_CNN.data_loader",
        "peekOfCode": "length_obc = np.array([2.0,7.5,5.0,5.0,6.0,4.3,4.5,5.0,3.8,4.5,4.9])\nwidth_obc = np.array([7.0, 5.0,3.0,5.0,5.0,4.7,4.7,6.8,7.0,4.0,4.6])\n# def load_dataset(N=30000,NP=1800):\ndef load_dataset_mask(N=120,NP=1800):\n    # obstacles=np.zeros((N,8800),dtype=np.float32)\n    # for i in range(0,N):\n    #     temp=np.fromfile('../../../DATA_SET/obs_cloud_for_CAE/obc_complex'+str(i)+'.dat')\n    #     temp=temp.reshape(len(temp)//2,2) #change/->// due to python3 by zheng\n    #     obstacles[i]=temp.flatten()\n##########################",
        "detail": "ATOA.AE_concave_2d_CNN.data_loader",
        "documentation": {}
    },
    {
        "label": "width_obc",
        "kind": 5,
        "importPath": "ATOA.AE_concave_2d_CNN.data_loader",
        "description": "ATOA.AE_concave_2d_CNN.data_loader",
        "peekOfCode": "width_obc = np.array([7.0, 5.0,3.0,5.0,5.0,4.7,4.7,6.8,7.0,4.0,4.6])\n# def load_dataset(N=30000,NP=1800):\ndef load_dataset_mask(N=120,NP=1800):\n    # obstacles=np.zeros((N,8800),dtype=np.float32)\n    # for i in range(0,N):\n    #     temp=np.fromfile('../../../DATA_SET/obs_cloud_for_CAE/obc_complex'+str(i)+'.dat')\n    #     temp=temp.reshape(len(temp)//2,2) #change/->// due to python3 by zheng\n    #     obstacles[i]=temp.flatten()\n##########################\n    # obc=np.zeros((N,11,2),dtype=np.float32)",
        "detail": "ATOA.AE_concave_2d_CNN.data_loader",
        "documentation": {}
    },
    {
        "label": "AutoEncoder",
        "kind": 6,
        "importPath": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "description": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "peekOfCode": "class AutoEncoder(nn.Module):\n    def __init__(self):\n        super(AutoEncoder, self).__init__()\n        self.encoder = AE.Encoder_CNN_2D(mask_size=160, dropout_p=0.0)\n        self.decoder = AE.Decoder_CNN_2D(dropout_p=0.0)\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n#Initialize the model",
        "detail": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "description": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "peekOfCode": "def train(model, dataloader, epochs):\n    model.train()\n    for epoch in range(epochs):\n        for inputs in dataloader:\n            #Assuming that the inputs are already the correct batch size x 1 x 160 x 160 tensor, and the elements are 0 or 1\n            outputs = autoencoder(inputs)\n            loss = criterion(outputs, inputs) \n            optimizer.zero_grad()\n            loss.backward() \n            optimizer.step()  ",
        "detail": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "documentation": {}
    },
    {
        "label": "autoencoder",
        "kind": 5,
        "importPath": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "description": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "peekOfCode": "autoencoder = AutoEncoder()\n#Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n#Training Autoencoder\ndef train(model, dataloader, epochs):\n    model.train()\n    for epoch in range(epochs):\n        for inputs in dataloader:\n            #Assuming that the inputs are already the correct batch size x 1 x 160 x 160 tensor, and the elements are 0 or 1",
        "detail": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "description": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "peekOfCode": "criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n#Training Autoencoder\ndef train(model, dataloader, epochs):\n    model.train()\n    for epoch in range(epochs):\n        for inputs in dataloader:\n            #Assuming that the inputs are already the correct batch size x 1 x 160 x 160 tensor, and the elements are 0 or 1\n            outputs = autoencoder(inputs)\n            loss = criterion(outputs, inputs) ",
        "detail": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "description": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "peekOfCode": "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n#Training Autoencoder\ndef train(model, dataloader, epochs):\n    model.train()\n    for epoch in range(epochs):\n        for inputs in dataloader:\n            #Assuming that the inputs are already the correct batch size x 1 x 160 x 160 tensor, and the elements are 0 or 1\n            outputs = autoencoder(inputs)\n            loss = criterion(outputs, inputs) \n            optimizer.zero_grad()",
        "detail": "ATOA.AE_R_3d_CNN.AutoEncoder",
        "documentation": {}
    },
    {
        "label": "Encoder_CNN_3D",
        "kind": 6,
        "importPath": "ATOA.AE_R_3d_CNN.CNN_3d",
        "description": "ATOA.AE_R_3d_CNN.CNN_3d",
        "peekOfCode": "class Encoder_CNN_3D(nn.Module):\n    def __init__(self, mask_size=160, dropout_p=0):\n        super(Encoder_CNN_3D, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv3d(1, 4, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(4), \n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            nn.Dropout(dropout_p), \n            nn.Conv3d(4, 8, kernel_size=3, stride=1, padding=1),",
        "detail": "ATOA.AE_R_3d_CNN.CNN_3d",
        "documentation": {}
    },
    {
        "label": "Encoder_CNN_3D_duplicate",
        "kind": 6,
        "importPath": "ATOA.AE_R_3d_CNN.CNN_3d",
        "description": "ATOA.AE_R_3d_CNN.CNN_3d",
        "peekOfCode": "class Encoder_CNN_3D_duplicate(nn.Module):\n    def __init__(self, mask_size=160, dropout_p=0):\n        super(Encoder_CNN_3D, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv3d(1, 4, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(4), \n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=2, stride=2),\n            nn.Dropout(dropout_p), \n            nn.Conv3d(4, 8, kernel_size=3, stride=1, padding=1),",
        "detail": "ATOA.AE_R_3d_CNN.CNN_3d",
        "documentation": {}
    },
    {
        "label": "Encoder",
        "kind": 6,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "class Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "Decoder",
        "kind": 6,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "class Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n#Interpolation function\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "interpolate_points",
        "kind": 2,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "def interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):\n    #Check array dimensions\n    if arr.ndim == 1:\n        #If it is a one-dimensional array, return 1 (because we assume that one-dimensional arrays always represent a single data point)\n        return 1\n    else:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "get_effective_length",
        "kind": 2,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "def get_effective_length(arr):\n    #Check array dimensions\n    if arr.ndim == 1:\n        #If it is a one-dimensional array, return 1 (because we assume that one-dimensional arrays always represent a single data point)\n        return 1\n    else:\n        #For multidimensional arrays, return the length of the first dimension\n        return len(arr)\n#N=number of environments; NP=Number of Paths  //for orientation version\ndef load_dataset_crossentropy(scale_para,bias,num_sector_theta,num_sector_phi,N=10,NP=4000,s=0,sp=0):\t",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "load_dataset_crossentropy",
        "kind": 2,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "def load_dataset_crossentropy(scale_para,bias,num_sector_theta,num_sector_phi,N=10,NP=4000,s=0,sp=0):\t\n\t## Calculate the longest set of boundary points\n\tmax_boundary_length=0\n\tboundary_lengths=np.zeros((N),dtype=int)\n\tfor i in range(0,N):\n\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" #Change the file name and path as needed\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" #Change the file name and path as needed\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_crossentropy",
        "kind": 2,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "def load_test_dataset_crossentropy(scale_para,bias,num_sector_theta,num_sector_phi,N=10, NP=200,s=100, sp=0):\t\n\t## Calculate the longest set of boundary points\n\tmax_boundary_length=0\n\tboundary_lengths=np.zeros((N),dtype=int)\n\tfor i in range(0,N):\n\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" #Change the file name and path as needed\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" #Change the file name and path as needed\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_planner",
        "kind": 2,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "def load_test_dataset_planner(scale_para,bias,N=10, NP=2000,s=100, sp=0): #change by z unseen environments\n#def load_test_dataset_new(scale_para,bias,N=100,NP=200, s=0,sp=4000):'\n\tobs_start=s\n\tobc=np.zeros((N,10,3),dtype=np.float32)\n\ttemp=np.fromfile('../../DATA_SET/r3d/obs.dat')\n\tobs=temp.reshape(len(temp)//3,3) #change by z\n\ttemp=np.fromfile('../../DATA_SET/r3d/obs_perm2.dat',np.int32)\n\tperm=temp.reshape(184756,10)\n\t## loading obstacles\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "length_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "length_obc = np.array([5,5,5,10,10,10,10,5,10,5])\nwidth_obc = np.array([5, 10,10,5,5,10,10,5,10,5])\nhigh_obc = np.array([10, 5,10,5,10,5,10,5,10,5])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "width_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "width_obc = np.array([5, 10,10,5,5,10,10,5,10,5])\nhigh_obc = np.array([10, 5,10,5,10,5,10,5,10,5])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "high_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "high_obc = np.array([10, 5,10,5,10,5,10,5,10,5])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tself.encoder",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n#Interpolation function",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tself.decoder",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n#Interpolation function\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tx = self.decoder(x)\n\t\treturn x\n#Interpolation function\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):\n    #Check array dimensions\n    if arr.ndim == 1:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" #Change the file name and path as needed\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" #Change the file name and path as needed\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,60),dtype=np.float32)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" #Change the file name and path as needed\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):\n\t\t\tfname='../../DATA_SET/r3d/Path_normal_narrow/e'+str(i+s)+'/path'+str(j+sp)+'.dat'",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdx",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tdx = path_reshape[k+1][0] - path_reshape[k][0]\n\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t#Calculate the modulus of a vector\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdy",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t#Calculate the modulus of a vector\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdz",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t#Calculate the modulus of a vector\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tr",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tphi",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_theta[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_phi[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:\n\t\t\t\tprint(\"Alert! No relevant files found.\")",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\tenv_indices",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\tenv_indices = []\n\tdataset=[]\n\tnew_dataset=[]\n\torient_dataset=[]\n\ttargets=[]\n\ttargets_future_all=[]\n\t# new_targets=[]\n\tclassification_orient_theta_targets=[]\n\tclassification_orient_phi_targets=[]\n\tclassification_norm_targets=[]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tall_interpolated_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tall_interpolated_points = []\n\t\t\t\t\tif path_lengths[i][j]>2:\n\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp2",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tinterpolated_segment",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\tmax_length_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\tpadded_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_array",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets=zip(*orient_data)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" #Change the file name and path as needed\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" #Change the file name and path as needed\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,60),dtype=np.float32)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" #Change the file name and path as needed\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):\n\t\t\tfname='../../DATA_SET/r3d/Path_normal_narrow/e'+str(i+s)+'/path'+str(j+sp)+'.dat'",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdx",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tdx = path_reshape[k+1][0] - path_reshape[k][0]\n\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t#Calculate the modulus of a vector\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdy",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t#Calculate the modulus of a vector\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdz",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t#Calculate the modulus of a vector\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tr",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t#Calculate θ (ensuring that r is not zero)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\ttheta = math.acos(dz / r)  #The output range of ACOS is [0, π]\n\t\t\t\t\t#Calculate ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tphi",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tphi = math.atan2(dy, dx)  #The output range of atan2 is [- π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_theta[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_phi[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:\n\t\t\t\tprint(\"Alert! No relevant files found.\")",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\tenv_indices",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\tenv_indices = []\n\tdataset=[]\n\tnew_dataset=[]\n\torient_dataset=[]\n\ttargets=[]\n\ttargets_future_all=[]\n\t# new_targets=[]\n\tclassification_orient_theta_targets=[]\n\tclassification_orient_phi_targets=[]\n\tclassification_norm_targets=[]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tall_interpolated_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\tall_interpolated_points = []\n\t\t\t\t\tif path_lengths[i][j]>2:\n\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp2",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tinterpolated_segment",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\tmax_length_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\tpadded_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_array",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets=zip(*orient_data)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = np.zeros((int(40*scale_para), int(40*scale_para),int(40*scale_para)))\n\t\tlength_obc_mask=length_obc*scale_para\n\t\twidth_obc_mask=width_obc*scale_para\n\t\thigh_obc_mask=high_obc*scale_para\n\t\tobc_mask=(obc[i]+bias)*scale_para\n\t\tfor j in range(0,10):\n\t\t\tcenter_x, center_y, center_z = obc_mask[j]\n\t\t\t#Calculate the boundary coordinates of obstacles\n\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tleft_x",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tright_x",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\ttop_y",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tbottom_y",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tlower_z",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tupper_z",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:\n\t\t# \tenviro[int(np.floor(obc_p[0])), int(np.floor(obc_p[1]))] = 1",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = ndimage.binary_fill_holes(enviro).astype(int) #mask\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\t# obs_rep=np.zeros((N,28),dtype=np.float32)\t",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\t# obs_rep=np.zeros((N,28),dtype=np.float32)\t\n\t# obs_recover=np.zeros((N,8800),dtype=np.float32)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\t# obs_rep=np.zeros((N,28),dtype=np.float32)\t\n\t# obs_recover=np.zeros((N,8800),dtype=np.float32)\n\tfor i in range(0,N): ",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = np.zeros((int(40*scale_para), int(40*scale_para),int(40*scale_para)))\n\t\tlength_obc_mask=length_obc*scale_para\n\t\twidth_obc_mask=width_obc*scale_para\n\t\thigh_obc_mask=high_obc*scale_para\n\t\tobc_mask=(obc[i]+bias)*scale_para\n\t\tfor j in range(0,10):\n\t\t\tcenter_x, center_y, center_z = obc_mask[j]\n\t\t\t#Calculate the boundary coordinates of obstacles\n\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tleft_x",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tright_x",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\ttop_y",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tbottom_y",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tlower_z",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\t\tupper_z",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:\n\t\t# \tenviro[int(np.floor(obc_p[0])), int(np.floor(obc_p[1]))] = 1",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tenviro = ndimage.binary_fill_holes(enviro).astype(int) #mask\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()\n\t\t# output=Q(inp)",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader",
        "description": "ATOA.data_loader",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()\n\t\t# output=Q(inp)\n\t\t# output=output.data.cpu()",
        "detail": "ATOA.data_loader",
        "documentation": {}
    },
    {
        "label": "Encoder",
        "kind": 6,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "class Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(8800,2200),nn.PReLU(),nn.Linear(2200, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 128),nn.PReLU(),nn.Linear(128, 28))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "Decoder",
        "kind": 6,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "class Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(28, 128),nn.PReLU(),nn.Linear(128, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 2200),nn.PReLU(),nn.Linear(2200, 8800))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "interpolate_points",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "def interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):\n    # 检查数组维度\n    if arr.ndim == 1:\n        # 如果是一维数组，返回1（因为我们假设一维数组总是表示单一数据点）\n        return 1\n    else:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "get_effective_length",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "def get_effective_length(arr):\n    # 检查数组维度\n    if arr.ndim == 1:\n        # 如果是一维数组，返回1（因为我们假设一维数组总是表示单一数据点）\n        return 1\n    else:\n        # 对于多维数组，返回第一维的长度\n        return len(arr)\n#N=number of environments; NP=Number of Paths  //for orientation version\n#def load_dataset_crossentropy(N=100,NP=4000):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "load_dataset_crossentropy",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "def load_dataset_crossentropy(scale_para,bias,num_sector,N=100,NP=4000,s=0, sp=0):\n\t# obc=np.zeros((N,11,2),dtype=np.float32)\n\t# temp=np.fromfile('../../DATA_SET/Concave_2D/obs.dat')\n\t# obs=temp.reshape(len(temp)//2,2) #change by z \n\t# # np.set_printoptions(threshold=100)\n\t# temp=np.fromfile('../../DATA_SET/Concave_2D/obs_perm_concave.dat',np.int32)\n\t# perm=temp.reshape(167960,11)\n\t# # To visualize the demonstration path\n\t# for i in range(0,N):\n\t# \tos.makedirs('./Ground_Truth_Path_Img/e'+str(i), exist_ok=True)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_crossentropy",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "def load_test_dataset_crossentropy(scale_para,bias,num_sector,N=10, NP=200,s=100, sp=0):\t\n\t# obc=np.zeros((N,11,2),dtype=np.float32)\n\t# temp=np.fromfile('../../DATA_SET/Concave_2D/obs.dat')\n\t# obs=temp.reshape(len(temp)//2,2) #change by z \n\t# temp=np.fromfile('../../DATA_SET/Concave_2D/obs_perm_concave.dat',np.int32)\n\t# perm=temp.reshape(167960,11)\n\t# ## loading obstacles\n\t# for i in range(0,N):\n\t# \tfor j in range(0,11):\n\t# \t\tfor k in range(0,2):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_planner",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "def load_test_dataset_planner(scale_para,bias,N=10, NP=2000,s=100, sp=0): #change by z unseen environments\n#def load_test_dataset_new(scale_para,bias,N=100,NP=200, s=0,sp=4000):'\n\tobs_start=s\n\tobc=np.zeros((N,11,2),dtype=np.float32)\n\ttemp=np.fromfile('../../DATA_SET/Concave_2D/obs.dat')\n\tobs=temp.reshape(len(temp)//2,2) #change by z \n\ttemp=np.fromfile('../../DATA_SET/Concave_2D/obs_perm_concave.dat',np.int32)\n\tperm=temp.reshape(167960,11)\n\t## loading obstacles\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "length_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "length_obc = np.array([2.0,7.5,5.0,5.0,6.0,4.3,4.5,5.0,3.8,4.5,4.9])\nwidth_obc = np.array([7.0, 5.0,3.0,5.0,5.0,4.7,4.7,6.8,7.0,4.0,4.6])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(8800,2200),nn.PReLU(),nn.Linear(2200, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 128),nn.PReLU(),nn.Linear(128, 28))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "width_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "width_obc = np.array([7.0, 5.0,3.0,5.0,5.0,4.7,4.7,6.8,7.0,4.0,4.6])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(8800,2200),nn.PReLU(),nn.Linear(2200, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 128),nn.PReLU(),nn.Linear(128, 28))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tself.encoder",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tself.encoder = nn.Sequential(nn.Linear(8800,2200),nn.PReLU(),nn.Linear(2200, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 128),nn.PReLU(),nn.Linear(128, 28))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(28, 128),nn.PReLU(),nn.Linear(128, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 2200),nn.PReLU(),nn.Linear(2200, 8800))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(28, 128),nn.PReLU(),nn.Linear(128, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 2200),nn.PReLU(),nn.Linear(2200, 8800))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tself.decoder",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tself.decoder = nn.Sequential(nn.Linear(28, 128),nn.PReLU(),nn.Linear(128, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 2200),nn.PReLU(),nn.Linear(2200, 8800))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):\n    # 检查数组维度\n    if arr.ndim == 1:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tfile_path = '../../DATA_SET/Concave_2D/obc_mask_concave_narrow/concave_enviro_' + str(i+s) + '.dat'  # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\t# # 打印加载的数组和形状（可以根据需要移除）\n\t\t# plt.imshow(enviro.T, cmap='gray', origin='lower')\n\t\t# plt.show()\n\t\t# # assert 0\n\t\t# print(\"Loaded enviro for index\", i, \":\", enviro)\n\t\t# print(\"Shape:\", enviro.shape)\n\t\t# print(\"enviro_loaded-enviro:\", enviro-enviro)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\t# # 打印加载的数组和形状（可以根据需要移除）\n\t\t# plt.imshow(enviro.T, cmap='gray', origin='lower')\n\t\t# plt.show()\n\t\t# # assert 0\n\t\t# print(\"Loaded enviro for index\", i, \":\", enviro)\n\t\t# print(\"Shape:\", enviro.shape)\n\t\t# print(\"enviro_loaded-enviro:\", enviro-enviro)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\t# # 打印加载的数组和形状（可以根据需要移除）\n\t\t# plt.imshow(enviro.T, cmap='gray', origin='lower')\n\t\t# plt.show()\n\t\t# # assert 0\n\t\t# print(\"Loaded enviro for index\", i, \":\", enviro)\n\t\t# print(\"Shape:\", enviro.shape)\n\t\t# print(\"enviro_loaded-enviro:\", enviro-enviro)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\t# print(enviro_mask_set.dtype)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\t# print(enviro_mask_set.dtype)\n\tobs_rep=np.zeros((N,28),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\t# print(enviro_mask_set.dtype)\n\tobs_rep=np.zeros((N,28),dtype=np.float32)\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tfile_path = '../../DATA_SET/Concave_2D/obc_mask_concave_narrow/concave_enviro_' + str(i+s) + '.dat'  # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\t# # 打印加载的数组和形状（可以根据需要移除）\n\t\t# print(\"Loaded enviro for index\", i, \":\", enviro)\n\t\t# print(\"Shape:\", enviro.shape)\n\t\t# print(\"enviro_loaded-enviro:\", enviro-enviro)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\t# # 打印加载的数组和形状（可以根据需要移除）\n\t\t# print(\"Loaded enviro for index\", i, \":\", enviro)\n\t\t# print(\"Shape:\", enviro.shape)\n\t\t# print(\"enviro_loaded-enviro:\", enviro-enviro)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\t# # 打印加载的数组和形状（可以根据需要移除）\n\t\t# print(\"Loaded enviro for index\", i, \":\", enviro)\n\t\t# print(\"Shape:\", enviro.shape)\n\t\t# print(\"enviro_loaded-enviro:\", enviro-enviro)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t# print(\"boundary_points\")\n\t\t# print(boundary_points)\n\t\t# print(boundary_points.shape)\n\t\t# print(len(boundary_points))\n\t\t# print(type(boundary_points))\n\t\t# print(\"max_boundary_length\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t# print(\"boundary_points\")\n\t\t# print(boundary_points)\n\t\t# print(boundary_points.shape)\n\t\t# print(len(boundary_points))\n\t\t# print(type(boundary_points))\n\t\t# print(\"max_boundary_length\")\n\t\t# print(max_boundary_length)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t# print(\"boundary_points\")\n\t\t# print(boundary_points)\n\t\t# print(boundary_points.shape)\n\t\t# print(len(boundary_points))\n\t\t# print(type(boundary_points))\n\t\t# print(\"max_boundary_length\")\n\t\t# print(max_boundary_length)\n\t\t# plt.scatter(boundary_points[:,0], boundary_points[:,1], c='red', s=1)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tenv_indices",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tenv_indices = []\n\tdataset=[]\n\tnew_dataset=[]\n\torient_dataset=[]\n\ttargets=[]\n\ttargets_future_all=[]\n\t# new_targets=[]\n\tclassification_orient_targets=[]\n\tclassification_norm_targets=[]\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tall_interpolated_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\tall_interpolated_points = []\n\t\t\t\t\tif path_lengths[i][j]>2:\n\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp2",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tinterpolated_segment",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t# print(\"222222\")\t\t\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t# print(\"222222\")\t\t\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\t# Method: Fill each array to make its length equal to the maximum length\n\t# print(\"max_length_targets_future_all\",max_length_targets_future_all)\n\t# assert 0\n\t# print(\"paths\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t# print(\"222222\")\t\t\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\t# Method: Fill each array to make its length equal to the maximum length\n\t# print(\"max_length_targets_future_all\",max_length_targets_future_all)\n\t# assert 0\n\t# print(\"paths\")\n\t# print(paths)\n\t# print(\"targets_future_all\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tmax_length_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\t# Method: Fill each array to make its length equal to the maximum length\n\t# print(\"max_length_targets_future_all\",max_length_targets_future_all)\n\t# assert 0\n\t# print(\"paths\")\n\t# print(paths)\n\t# print(\"targets_future_all\")\n\t# print(targets_future_all)\n\t# print(len(targets_future_all))\n\t# print(\"targets_future_all\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tpadded_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\t# print(\"33333\")\t\t\t\n\tprint(\"len(padded_targets_future_all)\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\t# print(\"33333\")\t\t\t\n\tprint(\"len(padded_targets_future_all)\")\n\t# print(padded_targets_future_all)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_array",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\t# print(\"33333\")\t\t\t\n\tprint(\"len(padded_targets_future_all)\")\n\t# print(padded_targets_future_all)\n\tprint(len(padded_targets_future_all))\n\tprint(\"dataset\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\t# print(\"33333\")\t\t\t\n\tprint(\"len(padded_targets_future_all)\")\n\t# print(padded_targets_future_all)\n\tprint(len(padded_targets_future_all))\n\tprint(\"dataset\")\n\tprint(len(dataset))",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\t# print(\"33333\")\t\t\t\n\tprint(\"len(padded_targets_future_all)\")\n\t# print(padded_targets_future_all)\n\tprint(len(padded_targets_future_all))\n\tprint(\"dataset\")\n\tprint(len(dataset))\n\t# print(\"padded_targets_future_all\")\n\t# print(padded_targets_future_all)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tfile_path = '../../DATA_SET/Concave_2D/obc_mask_concave_narrow/concave_enviro_' + str(i+s) + '.dat'  # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,28),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,28),dtype=np.float32)\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,28),dtype=np.float32)\n\tfor i in range(0,N):\n\t\t#load obstacle point cloud",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tfile_path = '../../DATA_SET/Concave_2D/obc_mask_concave_narrow/concave_enviro_' + str(i+s) + '.dat'  # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t#print(\"boundary_points\")\n\t\t#print(boundary_points)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t#print(\"boundary_points\")\n\t\t#print(boundary_points)\n\t\t#print(boundary_points.shape)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t#print(\"boundary_points\")\n\t\t#print(boundary_points)\n\t\t#print(boundary_points.shape)\n\t\t#print(len(boundary_points))",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t#print(\"boundary_points\")\n\t\t#print(boundary_points)\n\t\t#print(boundary_points.shape)\n\t\t#print(len(boundary_points))\n\t\t#print(type(boundary_points))\n\t\t#print(\"max_boundary_length\")",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t#print(\"boundary_points\")\n\t\t#print(boundary_points)\n\t\t#print(boundary_points.shape)\n\t\t#print(len(boundary_points))\n\t\t#print(type(boundary_points))\n\t\t#print(\"max_boundary_length\")\n\t\t#print(max_boundary_length)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\t#print(\"boundary_points\")\n\t\t#print(boundary_points)\n\t\t#print(boundary_points.shape)\n\t\t#print(len(boundary_points))\n\t\t#print(type(boundary_points))\n\t\t#print(\"max_boundary_length\")\n\t\t#print(max_boundary_length)\n\t\t#plt.scatter(boundary_points[:,0], boundary_points[:,1], c='red', s=1)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tenv_indices",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tenv_indices = []\n\tdataset=[]\n\tnew_dataset=[]\n\torient_dataset=[]\n\ttargets=[]\n\ttargets_future_all=[]\n\t# new_targets=[]\n\tclassification_orient_targets=[]\n\tclassification_norm_targets=[]\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tall_interpolated_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\tall_interpolated_points = []\n\t\t\t\t\tif path_lengths[i][j]>2:\n\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp2",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tinterpolated_segment",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.1) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tmax_length_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tpadded_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets))",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_array",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets=zip(*orient_data)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets=zip(*orient_data)\n\treturn \tenviro_mask_set,boundary_points_set,boundary_lengths,np.asarray(env_indices),np.asarray(dataset),np.asarray(targets),np.asarray(padded_targets_future_all),np.asarray(orient_dataset),np.asarray(classification_orient_targets),np.asarray(classification_norm_targets) ",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets=zip(*orient_data)\n\treturn \tenviro_mask_set,boundary_points_set,boundary_lengths,np.asarray(env_indices),np.asarray(dataset),np.asarray(targets),np.asarray(padded_targets_future_all),np.asarray(orient_dataset),np.asarray(classification_orient_targets),np.asarray(classification_norm_targets) \n# #N=number of environments; NP=Number of Paths\n# def load_dataset(N=100,NP=4000):",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tQ",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tQ = Encoder()\n\tD = Decoder()\n\tQ.load_state_dict(torch.load('./AE_complex/models/cae_encoder_concave_2d_300_average loss_2.102830.pkl'))\n\tD.load_state_dict(torch.load('./AE_complex/models/cae_decoder_concave_2d_300_average loss_2.102830.pkl'))\n\t# Q.load_state_dict(torch.load('../models/cae_encoder.pkl'))\n\t# D.load_state_dict(torch.load('../models/cae_decoder.pkl'))\n\tif torch.cuda.is_available():\n\t\tQ.cuda()\n\t\tD.cuda()\n\t## Calculate the longest set of boundary points",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\tD",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\tD = Decoder()\n\tQ.load_state_dict(torch.load('./AE_complex/models/cae_encoder_concave_2d_300_average loss_2.102830.pkl'))\n\tD.load_state_dict(torch.load('./AE_complex/models/cae_decoder_concave_2d_300_average loss_2.102830.pkl'))\n\t# Q.load_state_dict(torch.load('../models/cae_encoder.pkl'))\n\t# D.load_state_dict(torch.load('../models/cae_decoder.pkl'))\n\tif torch.cuda.is_available():\n\t\tQ.cuda()\n\t\tD.cuda()\n\t## Calculate the longest set of boundary points\n\tmax_boundary_length=0",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tfile_path = '../../DATA_SET/Concave_2D/obc_mask_narrow/narrow_enviro_' + str(i+s) + '.dat' # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,28),dtype=np.float32)\t",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,28),dtype=np.float32)\t\n\tobs_recover=np.zeros((N,8800),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,2),100, dtype=np.float32)   ## Take a very far point [100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,28),dtype=np.float32)\t\n\tobs_recover=np.zeros((N,8800),dtype=np.float32)\n\tfor i in range(0,N): ",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tfile_path = '../../DATA_SET/Concave_2D/obc_mask_narrow/narrow_enviro_' + str(i+s) + '.dat' # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,8800),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,8800),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = oh.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,8800),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,8800),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()\n\t\t# output=Q(inp)",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_concave_2d",
        "description": "ATOA.data_loader_crossentropy_concave_2d",
        "peekOfCode": "\t\tsurface_points = oh.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,8800),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()\n\t\t# output=Q(inp)\n\t\t# recover=D(output) #by z",
        "detail": "ATOA.data_loader_crossentropy_concave_2d",
        "documentation": {}
    },
    {
        "label": "Encoder",
        "kind": 6,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "class Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "Decoder",
        "kind": 6,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "class Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "interpolate_points",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "def interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):\n    # 检查数组维度\n    if arr.ndim == 1:\n        # 如果是一维数组，返回1（因为我们假设一维数组总是表示单一数据点）\n        return 1\n    else:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "get_effective_length",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "def get_effective_length(arr):\n    # 检查数组维度\n    if arr.ndim == 1:\n        # 如果是一维数组，返回1（因为我们假设一维数组总是表示单一数据点）\n        return 1\n    else:\n        # 对于多维数组，返回第一维的长度\n        return len(arr)\n#N=number of environments; NP=Number of Paths  //for orientation version\n#def load_dataset_crossentropy(N=100,NP=4000):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "load_dataset_crossentropy",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "def load_dataset_crossentropy(scale_para,bias,num_sector_theta,num_sector_phi,N=10,NP=4000,s=0,sp=0):\t\n\t## Calculate the longest set of boundary points\n\tmax_boundary_length=0\n\tboundary_lengths=np.zeros((N),dtype=int)\n\tfor i in range(0,N):\n\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" # 根据需要更改文件名和路径\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_crossentropy",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "def load_test_dataset_crossentropy(scale_para,bias,num_sector_theta,num_sector_phi,N=10, NP=200,s=100, sp=0):\t\n\t## Calculate the longest set of boundary points\n\tmax_boundary_length=0\n\tboundary_lengths=np.zeros((N),dtype=int)\n\tfor i in range(0,N):\n\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" # 根据需要更改文件名和路径\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "load_test_dataset_planner",
        "kind": 2,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "def load_test_dataset_planner(scale_para,bias,N=10, NP=2000,s=100, sp=0): #change by z unseen environments\n#def load_test_dataset_new(scale_para,bias,N=100,NP=200, s=0,sp=4000):'\n\tobs_start=s\n\tobc=np.zeros((N,10,3),dtype=np.float32)\n\ttemp=np.fromfile('../../DATA_SET/r3d/obs.dat')\n\tobs=temp.reshape(len(temp)//3,3) #change by z\n\ttemp=np.fromfile('../../DATA_SET/r3d/obs_perm2.dat',np.int32)\n\tperm=temp.reshape(184756,10)\n\t## loading obstacles\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "length_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "length_obc = np.array([5,5,5,10,10,10,10,5,10,5])\nwidth_obc = np.array([5, 10,10,5,5,10,10,5,10,5])\nhigh_obc = np.array([10, 5,10,5,10,5,10,5,10,5])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "width_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "width_obc = np.array([5, 10,10,5,5,10,10,5,10,5])\nhigh_obc = np.array([10, 5,10,5,10,5,10,5,10,5])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "high_obc",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "high_obc = np.array([10, 5,10,5,10,5,10,5,10,5])\nclass Encoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Encoder, self).__init__()\n\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tself.encoder",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tself.encoder = nn.Sequential(nn.Linear(6000, 786),nn.PReLU(),nn.Linear(786, 512),nn.PReLU(),nn.Linear(512, 256),nn.PReLU(),nn.Linear(256, 60))\n\tdef forward(self, x):\n\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tx = self.encoder(x)\n\t\treturn x\nclass Decoder(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Decoder, self).__init__()\n\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tself.decoder",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tself.decoder = nn.Sequential(nn.Linear(60, 256),nn.PReLU(),nn.Linear(256, 512),nn.PReLU(),nn.Linear(512, 786),nn.PReLU(),nn.Linear(786, 6000))\n\tdef forward(self, x):\n\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tx = self.decoder(x)\n\t\treturn x\n# 内插函数\ndef interpolate_points(p1, p2,distance_per_point):\n    distance = np.linalg.norm(p1 - p2)\n    num_points = int(distance / distance_per_point)\n    return np.linspace(p1, p2, num_points + 2)\ndef get_effective_length(arr):\n    # 检查数组维度\n    if arr.ndim == 1:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" # 根据需要更改文件名和路径\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,60),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):\n\t\t\tfname='../../DATA_SET/r3d/Path_normal_narrow/e'+str(i+s)+'/path'+str(j+sp)+'.dat'",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdx",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tdx = path_reshape[k+1][0] - path_reshape[k][0]\n\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t# 计算向量的模长\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdy",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t# 计算向量的模长\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdz",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t# 计算向量的模长\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tphi",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_theta[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_phi[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:\n\t\t\t\tprint(\"Alert! No relevant files found.\")",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\tenv_indices",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\tenv_indices = []\n\tdataset=[]\n\tnew_dataset=[]\n\torient_dataset=[]\n\ttargets=[]\n\ttargets_future_all=[]\n\t# new_targets=[]\n\tclassification_orient_theta_targets=[]\n\tclassification_orient_phi_targets=[]\n\tclassification_norm_targets=[]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tall_interpolated_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tall_interpolated_points = []\n\t\t\t\t\tif path_lengths[i][j]>2:\n\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp2",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tinterpolated_segment",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\tmax_length_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\tpadded_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_array",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets=zip(*orient_data)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" # 根据需要更改文件名和路径\n\t\t# file_path = f\"../../DATA_SET/r3d/obc_mask_3D/enviro_{i}.dat\" # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\t\t# print(\"boundary_points\",boundary_points,boundary_points.shape)\n\t\t# assert 0\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\tobs_rep=np.zeros((N,60),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tfile_path",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tfile_path = f\"../../DATA_SET/r3d/obc_mask_normal_narrow/enviro_{i+s}.dat\" # 根据需要更改文件名和路径\n\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tshape",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tshape = (int(40 * scale_para), int(40 * scale_para),int(40 * scale_para))\n\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = np.fromfile(file_path, dtype=int).reshape(shape)\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t## calculating length of the longest trajectory\n\tmax_length=0\n\tpath_lengths=np.zeros((N,NP),dtype=int)\n\tfor i in range(0,N):\n\t\tfor j in range(0,NP):\n\t\t\tfname='../../DATA_SET/r3d/Path_normal_narrow/e'+str(i+s)+'/path'+str(j+sp)+'.dat'",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdx",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tdx = path_reshape[k+1][0] - path_reshape[k][0]\n\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t# 计算向量的模长\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdy",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tdy = path_reshape[k+1][1] - path_reshape[k][1]\n\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t# 计算向量的模长\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tdz",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tdz = path_reshape[k+1][2] - path_reshape[k][2]\n\t\t\t\t\t# 计算向量的模长\n\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tr = math.sqrt(dx**2 + dy**2 + dz**2)\n\t\t\t\t\t# 计算θ (注意保证r不为零)\n\t\t\t\t\tif r == 0:\n\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\ttheta = 0\n\t\t\t\t\telse:\n\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\ttheta",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\ttheta = math.acos(dz / r)  # acos输出范围在[0, π]\n\t\t\t\t\t# 计算ϕ\n\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tphi",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tphi = math.atan2(dy, dx)  # atan2输出范围在[-π, π]\n\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_theta[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\torient_theta[i][j][k] = math.degrees(theta)\n\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\torient_phi[i][j][k]",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\torient_phi[i][j][k] = math.degrees(phi) \n\t\t\t\t\tnorm[i][j][k]=r\n\t\t\t\t\tindex_theta=int(orient_theta[i][j][k]//(180/accuracy_theta))\n\t\t\t\t\tindex_phi=int(orient_phi[i][j][k]//(360/accuracy_phi)+accuracy_phi/2)\n\t\t\t\t\torient_theta_classification[i][j][k][index_theta]=1.0\n\t\t\t\t\torient_phi_classification[i][j][k][index_phi]=1.0\n\t\t\t\t\torient_theta_index[i][j][k]=index_theta\n\t\t\t\t\torient_phi_index[i][j][k]=index_phi\n\t\t\telse:\n\t\t\t\tprint(\"Alert! No relevant files found.\")",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\tenv_indices",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\tenv_indices = []\n\tdataset=[]\n\tnew_dataset=[]\n\torient_dataset=[]\n\ttargets=[]\n\ttargets_future_all=[]\n\t# new_targets=[]\n\tclassification_orient_theta_targets=[]\n\tclassification_orient_phi_targets=[]\n\tclassification_norm_targets=[]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tall_interpolated_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\tall_interpolated_points = []\n\t\t\t\t\tif path_lengths[i][j]>2:\n\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1] #next point\n\t\t\t\t\t\tfor n in range(m+1, path_lengths[i][j]-1):\n\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp2",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\t\tp2 = paths[i][j][n+1]\n\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tinterpolated_segment",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\t\tinterpolated_segment = interpolate_points(p1, p2, 0.2) #not include p1 but include p2\n\t\t\t\t\t\t\tall_interpolated_points.extend(interpolated_segment)\n\t\t\t\t\t\t\t# all_interpolated_points.extend(p2)\n\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\t\tp1 = p2\n\t\t\t\t\t\tif (m+1)==path_lengths[i][j]-1:\n\t\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\t\t\t\t\t\t# targets_future_all.append(numpy_array_of_points)\n\t\t\t\t\telif path_lengths[i][j]>1:\n\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tp1",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tp1 = paths[i][j][m+1]\n\t\t\t\t\t\tall_interpolated_points.extend(p1)\n\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\tnumpy_array_of_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\t\t\t\tnumpy_array_of_points = np.array(all_interpolated_points)  \n\t\t\t\t\t\ttargets_future_all.append(numpy_array_of_points)\n\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\tmax_length_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\tmax_length_targets_future_all = max(get_effective_length(arr) for arr in targets_future_all)\t\n\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\tpadded_targets_future_all",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\tpadded_targets_future_all = []\n\tfor arr in targets_future_all:\n\t\tif arr.ndim == 1:\n\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(np.expand_dims(arr, axis=0))  #Length to be filled\n\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadding_value = np.expand_dims(arr, axis=0)[-1,:]\n\t\telse:\n\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpad_length",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpad_length = max_length_targets_future_all - len(arr)  #Length to be filled\n\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_value",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadding_value = arr[-1,:]\n\t\tif pad_length > 0:\n\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadding_array",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadding_array = np.repeat([padding_value], pad_length, axis=0)\n\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadded_arr = np.vstack((arr, padding_array))\n\t\telse:\n\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tpadded_arr",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tpadded_arr = arr\n\t\tpadded_targets_future_all.append(padded_arr)\n\tnew_dataset=dataset[:]\n\torient_dataset=\tdataset[:]\t\n\tprint(\"max_length_targets_future_all\",max_length_targets_future_all)\n\tprint(\"max_boundary_length\",max_boundary_length)\n\t# assert 0\n\torient_data=list(zip(env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets))\n\trandom.shuffle(orient_data)\n\tenv_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets=zip(*orient_data)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = np.zeros((int(40*scale_para), int(40*scale_para),int(40*scale_para)))\n\t\tlength_obc_mask=length_obc*scale_para\n\t\twidth_obc_mask=width_obc*scale_para\n\t\thigh_obc_mask=high_obc*scale_para\n\t\tobc_mask=(obc[i]+bias)*scale_para\n\t\tfor j in range(0,10):\n\t\t\tcenter_x, center_y, center_z = obc_mask[j]\n\t\t\t# 计算障碍物的边界坐标\n\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tleft_x",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tright_x",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\ttop_y",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tbottom_y",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tlower_z",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tupper_z",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:\n\t\t# \tenviro[int(np.floor(obc_p[0])), int(np.floor(obc_p[1]))] = 1",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = ndimage.binary_fill_holes(enviro).astype(int) #mask\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\t# obs_rep=np.zeros((N,28),dtype=np.float32)\t",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\t# obs_rep=np.zeros((N,28),dtype=np.float32)\t\n\t# obs_recover=np.zeros((N,8800),dtype=np.float32)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para) \n\t\tboundary_lengths[i]=len(boundary_points)\n\t\tif len(boundary_points)>max_boundary_length:\n\t\t\tmax_boundary_length=len(boundary_points)\n\tboundary_points_set=np.full((N,max_boundary_length,3),100, dtype=np.float32)   ## Take a very far point [100,100,100] so that it does not affect subsequent operations\n\tenviro_mask_set=np.zeros((N,int(40*scale_para), int(40*scale_para), int(40*scale_para)))\n\t# obs_rep=np.zeros((N,28),dtype=np.float32)\t\n\t# obs_recover=np.zeros((N,8800),dtype=np.float32)\n\tfor i in range(0,N): ",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = np.zeros((int(40*scale_para), int(40*scale_para),int(40*scale_para)))\n\t\tlength_obc_mask=length_obc*scale_para\n\t\twidth_obc_mask=width_obc*scale_para\n\t\thigh_obc_mask=high_obc*scale_para\n\t\tobc_mask=(obc[i]+bias)*scale_para\n\t\tfor j in range(0,10):\n\t\t\tcenter_x, center_y, center_z = obc_mask[j]\n\t\t\t# 计算障碍物的边界坐标\n\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tleft_x",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tleft_x = int(np.floor(center_x - length_obc_mask[j] / 2))\n\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tright_x",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tright_x = int(np.ceil(center_x + length_obc_mask[j] / 2))\n\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\ttop_y",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\ttop_y = int(np.floor(center_y - width_obc_mask[j] / 2))\n\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tbottom_y",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tbottom_y = int(np.ceil(center_y + width_obc_mask[j] / 2))\n\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tlower_z",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tlower_z = int(np.floor(center_z - high_obc_mask[j] / 2))\n\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\t\tupper_z",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\t\tupper_z = int(np.ceil(center_z + high_obc_mask[j] / 2))\t\n\t\t\tfor x in range(left_x, right_x + 1):\n\t\t\t\t\tfor y in range(top_y, bottom_y + 1):\n\t\t\t\t\t\tfor z in range(lower_z, upper_z + 1):\t\n\t\t\t\t\t\t\t# if 0 <= x < enviro.shape[0] and 0 <= y < enviro.shape[1] and 0 <= z < enviro.shape[2]:\n\t\t\t\t\t\t\tenviro[x, y, z] = 1\n\t\t# obc_add = np.add(temp, bias)\n\t\t# obc_mul = obc_add * scale_para\n\t\t# for obc_p in obc_mul:\n\t\t# \tenviro[int(np.floor(obc_p[0])), int(np.floor(obc_p[1]))] = 1",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tenviro",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tenviro = ndimage.binary_fill_holes(enviro).astype(int) #mask\n\t\tenviro_mask_set[i]=enviro\n\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = oh_3d.sample_inner_surface_in_pixel(torch.from_numpy(enviro))\n\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface = surface.cpu().numpy()\n\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()\n\t\t# output=Q(inp)",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "\t\tsurface_points",
        "kind": 5,
        "importPath": "ATOA.data_loader_crossentropy_R_3d",
        "description": "ATOA.data_loader_crossentropy_R_3d",
        "peekOfCode": "\t\tsurface_points = oh_3d.SamplesFunc(surface) #Extract inner surface points\n\t\tboundary_points=oh_3d.surface_to_real(surface_points,bias,scale_para)  #numpy.ndarray\n\t\tfor k in range(0,len(boundary_points)):\n\t\t\tboundary_points_set[i][k]=boundary_points[k]\n\t\t# obstacles=np.zeros((1,6000),dtype=np.float32)\n\t\t# obstacles[0]=temp.flatten()\n\t\t# inp=torch.from_numpy(obstacles)\n\t\t# inp=Variable(inp).cuda()\n\t\t# output=Q(inp)\n\t\t# output=output.data.cpu()",
        "detail": "ATOA.data_loader_crossentropy_R_3d",
        "documentation": {}
    },
    {
        "label": "MLP",
        "kind": 6,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "class MLP(nn.Module):\n\tdef __init__(self, input_size,num_sector,dropout_p=0):\n\t\tsuper(MLP, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(512, 384),nn.PReLU()) #need PReLU?",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "MLP_original",
        "kind": 6,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "class MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tself.fc",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(512, 384),nn.PReLU()) #need PReLU?\n\t\tself.fc1=nn.Sequential(\n\t\tnn.Linear(384, 1280),nn.PReLU(), nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 640),nn.PReLU(), nn.Dropout(p=dropout_p),",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tself.softmax_layer",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tself.softmax_layer = nn.Softmax(dim=-1)\n\t\tprint(\"mlp_hyper_parameter:\")\n\t\tprint(\"dropout_p\")\n\t\tprint(dropout_p)\n\tdef forward(self,x):\n\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\t# out_norm = torch.relu(self.fc1(out_temp))\n\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tout_temp",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\t# out_norm = torch.relu(self.fc1(out_temp))\n\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tout_norm",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tout_norm = self.fc1(out_temp)\n\t\t# out_norm = torch.relu(self.fc1(out_temp))\n\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_raw",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_softm",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tself.fc",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(384, 256),nn.PReLU(), nn.Dropout(),\n\t\tnn.Linear(256, 256),nn.PReLU(), nn.Dropout(),\n\t\tnn.Linear(256, 128),nn.PReLU(), nn.Dropout(),",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "\t\tout",
        "kind": 5,
        "importPath": "ATOA.model",
        "description": "ATOA.model",
        "peekOfCode": "\t\tout = self.fc(x)\n\t\treturn out",
        "detail": "ATOA.model",
        "documentation": {}
    },
    {
        "label": "MLP",
        "kind": 6,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "class MLP(nn.Module):\n\tdef __init__(self, input_size,num_sector,dropout_p=0):\n\t\tsuper(MLP, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(512, 384),nn.PReLU()) #need PReLU?",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "MLP_original",
        "kind": 6,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "class MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tself.fc",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(512, 384),nn.PReLU()) #need PReLU?\n\t\tself.fc1=nn.Sequential(\n\t\tnn.Linear(384, 1280),nn.PReLU(), nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 640),nn.PReLU(), nn.Dropout(p=dropout_p),",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tself.softmax_layer",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tself.softmax_layer = nn.Softmax(dim=-1)\n\t\tprint(\"mlp_hyper_parameter:\")\n\t\tprint(\"dropout_p\")\n\t\tprint(dropout_p)\n\tdef forward(self,x):\n\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\t# out_norm = torch.relu(self.fc1(out_temp))\n\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tout_temp",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\t# out_norm = torch.relu(self.fc1(out_temp))\n\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tout_norm",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tout_norm = self.fc1(out_temp)\n\t\t# out_norm = torch.relu(self.fc1(out_temp))\n\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_raw",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tout_orient_raw = self.fc2(out_temp)\n\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_softm",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tout_orient_softm = self.softmax_layer(out_orient_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_raw, out_orient_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tself.fc",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(384, 256),nn.PReLU(), nn.Dropout(),\n\t\tnn.Linear(256, 256),nn.PReLU(), nn.Dropout(),\n\t\tnn.Linear(256, 128),nn.PReLU(), nn.Dropout(),",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "\t\tout",
        "kind": 5,
        "importPath": "ATOA.model_2D",
        "description": "ATOA.model_2D",
        "peekOfCode": "\t\tout = self.fc(x)\n\t\treturn out",
        "detail": "ATOA.model_2D",
        "documentation": {}
    },
    {
        "label": "MLP_3D",
        "kind": 6,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "class MLP_3D(nn.Module):\n\tdef __init__(self, input_size,num_sector_theta,num_sector_phi,dropout_p=0):\n\t\tsuper(MLP_3D, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 896),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(512, 384),nn.PReLU()) #need PReLU?\n\t\tself.fc1=nn.Sequential(",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "MLP_original",
        "kind": 6,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "class MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tself.fc",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(1280, 896),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(p=dropout_p),\n\t\tnn.Linear(512, 384),nn.PReLU()) #need PReLU?\n\t\tself.fc1=nn.Sequential(\n\t\tnn.Linear(384, 320),nn.PReLU(), nn.Dropout(p=dropout_p),\n\t\tnn.Linear(320, 160),nn.PReLU(), nn.Dropout(p=dropout_p),\n\t\tnn.Linear(160, 32),nn.PReLU(),nn.Dropout(p=dropout_p),",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tself.softmax_layer1",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tself.softmax_layer1 = nn.Softmax(dim=-1)\n\t\tself.softmax_layer2 = nn.Softmax(dim=-1)\n\t\tprint(\"Planner_hyper_parameters:\")\n\t\tprint(\"dropout_p:\", dropout_p)\n\tdef forward(self,x):\n\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\tout_orient_theta_raw = self.fc2(out_temp)\n\t\tout_orient_phi_raw = self.fc3(out_temp)\n\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tself.softmax_layer2",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tself.softmax_layer2 = nn.Softmax(dim=-1)\n\t\tprint(\"Planner_hyper_parameters:\")\n\t\tprint(\"dropout_p:\", dropout_p)\n\tdef forward(self,x):\n\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\tout_orient_theta_raw = self.fc2(out_temp)\n\t\tout_orient_phi_raw = self.fc3(out_temp)\n\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)\n\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout_temp",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout_temp = self.fc(x)\n\t\tout_norm = self.fc1(out_temp)\n\t\tout_orient_theta_raw = self.fc2(out_temp)\n\t\tout_orient_phi_raw = self.fc3(out_temp)\n\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)\n\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_theta_raw,out_orient_phi_raw, out_orient_theta_softm,out_orient_phi_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout_norm",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout_norm = self.fc1(out_temp)\n\t\tout_orient_theta_raw = self.fc2(out_temp)\n\t\tout_orient_phi_raw = self.fc3(out_temp)\n\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)\n\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_theta_raw,out_orient_phi_raw, out_orient_theta_softm,out_orient_phi_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_theta_raw",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout_orient_theta_raw = self.fc2(out_temp)\n\t\tout_orient_phi_raw = self.fc3(out_temp)\n\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)\n\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_theta_raw,out_orient_phi_raw, out_orient_theta_softm,out_orient_phi_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_phi_raw",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout_orient_phi_raw = self.fc3(out_temp)\n\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)\n\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_theta_raw,out_orient_phi_raw, out_orient_theta_softm,out_orient_phi_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_theta_softm",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout_orient_theta_softm = self.softmax_layer1(out_orient_theta_raw)\n\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_theta_raw,out_orient_phi_raw, out_orient_theta_softm,out_orient_phi_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout_orient_phi_softm",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout_orient_phi_softm = self.softmax_layer2(out_orient_phi_raw)\n\t\t#out_label=torch.argmax(out_orient_soft,dim=1)\n\t\treturn out_norm, out_orient_theta_raw,out_orient_phi_raw, out_orient_theta_softm,out_orient_phi_softm\n# DMLP Model-Path Generator \nclass MLP_original(nn.Module):\n\tdef __init__(self, input_size, output_size):\n\t\tsuper(MLP_original, self).__init__()\n\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tself.fc",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tself.fc = nn.Sequential(\n\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),\n\t\tnn.Linear(384, 256),nn.PReLU(), nn.Dropout(),\n\t\tnn.Linear(256, 256),nn.PReLU(), nn.Dropout(),\n\t\tnn.Linear(256, 128),nn.PReLU(), nn.Dropout(),",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "\t\tout",
        "kind": 5,
        "importPath": "ATOA.model_R_3D",
        "description": "ATOA.model_R_3D",
        "peekOfCode": "\t\tout = self.fc(x)\n\t\treturn out",
        "detail": "ATOA.model_R_3D",
        "documentation": {}
    },
    {
        "label": "sample_outer_surface_in_pixel",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling",
        "description": "ATOA.obstacle_handling",
        "peekOfCode": "def sample_outer_surface_in_pixel(image): \n    a = F.max_pool2d(image[None,None].float(), kernel_size=(3,1), stride=1, padding=(1,0))[0]\n    b = F.max_pool2d(image[None,None].float(), kernel_size=(1,3), stride=1, padding=(0,1))[0]\n    border, _ = torch.max(torch.cat([a,b],dim=0),dim=0) \n    surface = border - image.float()\n    return surface.long()\ndef sample_inner_surface_in_pixel(image): \n    a = F.max_pool2d(-image[None,None].float(), kernel_size=(3,1), stride=1, padding=(1,0))[0]\n    b = F.max_pool2d(-image[None,None].float(), kernel_size=(1,3), stride=1, padding=(0,1))[0]\n    border, _ = torch.max(torch.cat([a,b],dim=0),dim=0) ",
        "detail": "ATOA.obstacle_handling",
        "documentation": {}
    },
    {
        "label": "sample_inner_surface_in_pixel",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling",
        "description": "ATOA.obstacle_handling",
        "peekOfCode": "def sample_inner_surface_in_pixel(image): \n    a = F.max_pool2d(-image[None,None].float(), kernel_size=(3,1), stride=1, padding=(1,0))[0]\n    b = F.max_pool2d(-image[None,None].float(), kernel_size=(1,3), stride=1, padding=(0,1))[0]\n    border, _ = torch.max(torch.cat([a,b],dim=0),dim=0) \n    surface = border + image.float()\n    return surface.long()\ndef SamplesFunc(img, value=1, type='array'):\n    samples_points = np.where(img == value)\n    samples = list(zip(list(samples_points[0]),list(samples_points[1])))\n    # print(\"samples\")",
        "detail": "ATOA.obstacle_handling",
        "documentation": {}
    },
    {
        "label": "SamplesFunc",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling",
        "description": "ATOA.obstacle_handling",
        "peekOfCode": "def SamplesFunc(img, value=1, type='array'):\n    samples_points = np.where(img == value)\n    samples = list(zip(list(samples_points[0]),list(samples_points[1])))\n    # print(\"samples\")\n    # print(samples)\n    if type=='list':\n        return samples \n    elif type=='array':\n        return np.array(samples)\ndef surface_to_real(surface_points,bias,scale_para):",
        "detail": "ATOA.obstacle_handling",
        "documentation": {}
    },
    {
        "label": "surface_to_real",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling",
        "description": "ATOA.obstacle_handling",
        "peekOfCode": "def surface_to_real(surface_points,bias,scale_para):\n    real_points=surface_points/scale_para\n    real_points=np.subtract(real_points,bias)\n    return real_points",
        "detail": "ATOA.obstacle_handling",
        "documentation": {}
    },
    {
        "label": "sample_outer_surface_in_pixel",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling_3d",
        "description": "ATOA.obstacle_handling_3d",
        "peekOfCode": "def sample_outer_surface_in_pixel(image): \n    a = F.max_pool3d(image[None,None].float(), kernel_size=(3,1,1), stride=1, padding=(1,0,0))[0]\n    b = F.max_pool3d(image[None,None].float(), kernel_size=(1,3,1), stride=1, padding=(0,1,0))[0]\n    c = F.max_pool3d(image[None,None].float(), kernel_size=(1,1,3), stride=1, padding=(0,0,1))[0]\n    border, _ = torch.max(torch.cat([a,b,c],dim=0),dim=0)\n    surface = border - image.float()\n    return surface.long()\ndef sample_inner_surface_in_pixel(image): \n    a = F.max_pool3d(-image[None,None].float(), kernel_size=(3,1,1), stride=1, padding=(1,0,0))[0]\n    b = F.max_pool3d(-image[None,None].float(), kernel_size=(1,3,1), stride=1, padding=(0,1,0))[0]",
        "detail": "ATOA.obstacle_handling_3d",
        "documentation": {}
    },
    {
        "label": "sample_inner_surface_in_pixel",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling_3d",
        "description": "ATOA.obstacle_handling_3d",
        "peekOfCode": "def sample_inner_surface_in_pixel(image): \n    a = F.max_pool3d(-image[None,None].float(), kernel_size=(3,1,1), stride=1, padding=(1,0,0))[0]\n    b = F.max_pool3d(-image[None,None].float(), kernel_size=(1,3,1), stride=1, padding=(0,1,0))[0]\n    c = F.max_pool3d(-image[None,None].float(), kernel_size=(1,1,3), stride=1, padding=(0,0,1))[0]\n    border, _ = torch.max(torch.cat([a,b,c],dim=0),dim=0)\n    surface = border + image.float()\n    return surface.long()\ndef SamplesFunc(img, value=1, type='array'):\n    samples_points = np.where(img == value)\n    samples = list(zip(list(samples_points[0]),list(samples_points[1]),list(samples_points[2])))",
        "detail": "ATOA.obstacle_handling_3d",
        "documentation": {}
    },
    {
        "label": "SamplesFunc",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling_3d",
        "description": "ATOA.obstacle_handling_3d",
        "peekOfCode": "def SamplesFunc(img, value=1, type='array'):\n    samples_points = np.where(img == value)\n    samples = list(zip(list(samples_points[0]),list(samples_points[1]),list(samples_points[2])))\n    if type=='list':\n        return samples \n    elif type=='array':\n        return np.array(samples)\ndef SamplesFunc1(img, value=1, type='array', step=2):\n    samples_points = np.where(img[::step, ::step, ::step] == value)\n    samples_points_adjusted = tuple([points * step for points in samples_points])",
        "detail": "ATOA.obstacle_handling_3d",
        "documentation": {}
    },
    {
        "label": "SamplesFunc1",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling_3d",
        "description": "ATOA.obstacle_handling_3d",
        "peekOfCode": "def SamplesFunc1(img, value=1, type='array', step=2):\n    samples_points = np.where(img[::step, ::step, ::step] == value)\n    samples_points_adjusted = tuple([points * step for points in samples_points])\n    samples = list(zip(*samples_points_adjusted))\n    if type == 'list':\n        return samples\n    elif type == 'array':\n        return np.array(samples)\ndef surface_to_real(surface_points,bias,scale_para):\n    real_points=surface_points/scale_para",
        "detail": "ATOA.obstacle_handling_3d",
        "documentation": {}
    },
    {
        "label": "surface_to_real",
        "kind": 2,
        "importPath": "ATOA.obstacle_handling_3d",
        "description": "ATOA.obstacle_handling_3d",
        "peekOfCode": "def surface_to_real(surface_points,bias,scale_para):\n    real_points=surface_points/scale_para\n    real_points=np.subtract(real_points,bias)\n    return real_points",
        "detail": "ATOA.obstacle_handling_3d",
        "documentation": {}
    },
    {
        "label": "create_env_mask",
        "kind": 2,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "def create_env_mask(env_dict, img_size=IMG_SIZE):\n    H, W = img_size\n    mask = np.zeros((H, W), dtype=np.float32)\n    for rect in env_dict.get(\"rectangle_obstacles\", []):\n        x, y, w, h = rect\n        xs = np.array([x, x + w, x + w, x])\n        ys = np.array([y, y, y + h, y + h])\n        xs = (xs / env_dict[\"env_dims\"][0] * (W - 1)).astype(np.int32)\n        ys = (ys / env_dict[\"env_dims\"][1] * (H - 1)).astype(np.int32)\n        rr, cc = polygon(ys, xs, shape=mask.shape)",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "compute_boundary_points",
        "kind": 2,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "def compute_boundary_points(env_dict, num_points=50):\n    points = []\n    for rect in env_dict.get(\"rectangle_obstacles\", []):\n        x, y, w, h = rect\n        for xi in np.linspace(x, x + w, num=num_points//4, endpoint=False):\n            points.append([xi, y])\n            points.append([xi, y + h])\n        for yi in np.linspace(y, y + h, num=num_points//4, endpoint=False):\n            points.append([x, yi])\n            points.append([x + w, yi])",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "direction_to_class",
        "kind": 2,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "def direction_to_class(start, goal, num_sectors=NUM_SECTORS):\n    vec = np.array(goal) - np.array(start)\n    angle = np.arctan2(vec[1], vec[0])\n    sector = int(((angle + np.pi) / (2 * np.pi)) * num_sectors)\n    return sector % num_sectors\n# ---------------- 主函数 ----------------\nfor dataset in DATASETS:\n    DATA_DIR = os.path.join(BASE_DIR, dataset)\n    JSON_FILE = os.path.join(DATA_DIR, \"envs.json\")\n    PROCESSED_DIR = os.path.join(SAVE_DIR, dataset)",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "BASE_DIR = \"data/random_2d\"  # 数据集总目录\nSAVE_DIR = os.path.join(BASE_DIR, \"processed_all\")\nos.makedirs(SAVE_DIR, exist_ok=True)\nIMG_SIZE = (140, 140)  # CNN输入掩码大小\nNUM_SECTORS = 8         # 方向分类数\nDATASETS = [\"train\", \"val\", \"test\"]\n# ---------------- 工具函数 ----------------\ndef create_env_mask(env_dict, img_size=IMG_SIZE):\n    H, W = img_size\n    mask = np.zeros((H, W), dtype=np.float32)",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "SAVE_DIR",
        "kind": 5,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "SAVE_DIR = os.path.join(BASE_DIR, \"processed_all\")\nos.makedirs(SAVE_DIR, exist_ok=True)\nIMG_SIZE = (140, 140)  # CNN输入掩码大小\nNUM_SECTORS = 8         # 方向分类数\nDATASETS = [\"train\", \"val\", \"test\"]\n# ---------------- 工具函数 ----------------\ndef create_env_mask(env_dict, img_size=IMG_SIZE):\n    H, W = img_size\n    mask = np.zeros((H, W), dtype=np.float32)\n    for rect in env_dict.get(\"rectangle_obstacles\", []):",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "IMG_SIZE",
        "kind": 5,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "IMG_SIZE = (140, 140)  # CNN输入掩码大小\nNUM_SECTORS = 8         # 方向分类数\nDATASETS = [\"train\", \"val\", \"test\"]\n# ---------------- 工具函数 ----------------\ndef create_env_mask(env_dict, img_size=IMG_SIZE):\n    H, W = img_size\n    mask = np.zeros((H, W), dtype=np.float32)\n    for rect in env_dict.get(\"rectangle_obstacles\", []):\n        x, y, w, h = rect\n        xs = np.array([x, x + w, x + w, x])",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "NUM_SECTORS",
        "kind": 5,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "NUM_SECTORS = 8         # 方向分类数\nDATASETS = [\"train\", \"val\", \"test\"]\n# ---------------- 工具函数 ----------------\ndef create_env_mask(env_dict, img_size=IMG_SIZE):\n    H, W = img_size\n    mask = np.zeros((H, W), dtype=np.float32)\n    for rect in env_dict.get(\"rectangle_obstacles\", []):\n        x, y, w, h = rect\n        xs = np.array([x, x + w, x + w, x])\n        ys = np.array([y, y, y + h, y + h])",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "DATASETS",
        "kind": 5,
        "importPath": "ATOA.prepare_all_datasets",
        "description": "ATOA.prepare_all_datasets",
        "peekOfCode": "DATASETS = [\"train\", \"val\", \"test\"]\n# ---------------- 工具函数 ----------------\ndef create_env_mask(env_dict, img_size=IMG_SIZE):\n    H, W = img_size\n    mask = np.zeros((H, W), dtype=np.float32)\n    for rect in env_dict.get(\"rectangle_obstacles\", []):\n        x, y, w, h = rect\n        xs = np.array([x, x + w, x + w, x])\n        ys = np.array([y, y, y + h, y + h])\n        xs = (xs / env_dict[\"env_dims\"][0] * (W - 1)).astype(np.int32)",
        "detail": "ATOA.prepare_all_datasets",
        "documentation": {}
    },
    {
        "label": "angle_norm_to_coordinate",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[60] + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[61]+ torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[62] + torch.cos(theta) * out_norm\t\n\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "orient_norm_to_coordinate",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\tnext_point[1]=last_point[1]+math.sin(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\treturn next_point\ndef r3d_plot_path(fp,path,size_start_end,marker_start,color,plot_color_count,marker_end,size_generate,paths,path_lengths,size_act,i,j,ax1):\n\tprint(path)\n\tif fp==1: #feasible path without replan\n\t\tax1.scatter(path[0,0], path[0,1],path[0,2], s=size_start_end,marker=marker_start, c=color[plot_color_count])\n\t\tax1.scatter(path[len(path)-1,0], path[len(path)-1,1],path[len(path)-1,2], s=size_start_end,marker=marker_end,c=color[plot_color_count])",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "r3d_plot_path",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def r3d_plot_path(fp,path,size_start_end,marker_start,color,plot_color_count,marker_end,size_generate,paths,path_lengths,size_act,i,j,ax1):\n\tprint(path)\n\tif fp==1: #feasible path without replan\n\t\tax1.scatter(path[0,0], path[0,1],path[0,2], s=size_start_end,marker=marker_start, c=color[plot_color_count])\n\t\tax1.scatter(path[len(path)-1,0], path[len(path)-1,1],path[len(path)-1,2], s=size_start_end,marker=marker_end,c=color[plot_color_count])\n\t\tax1.scatter(path[:,0], path[:,1],path[:,2],s=size_generate,marker='o', c=color[plot_color_count])\n\t\tax1.plot(path[:,0], path[:,1],path[:,2],linewidth=3.0,c=color[plot_color_count])\n\t\t#demonstrate the BIT* paths\n\t\tax1.scatter(paths[i][j][:path_lengths[i][j]][:,0], paths[i][j][:path_lengths[i][j]][:,1], paths[i][j][:path_lengths[i][j]][:,2],s=size_act,marker='d', c=color[plot_color_count]) #!!!!!!!\n\t\tax1.plot(paths[i][j][:path_lengths[i][j]][:,0], paths[i][j][:path_lengths[i][j]][:,1], paths[i][j][:path_lengths[i][j]][:,2],linestyle=':',c=color[plot_color_count])",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "r3d_plot_cloud",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def r3d_plot_cloud(obs,i,s,ax1):\n    # could_plt=obs[i].detach().cpu().numpy()\n    temp=np.fromfile('../../DATA_SET/r3d/obs_cloud_3D_narrow/obc_3D_narrow'+str(i+s)+'.dat') \n    could_plt=temp.reshape(len(temp)//3,3) \t\t\n    ax1.scatter(could_plt[:,0], could_plt[:,1],could_plt[:,2], c='b')\n    ax1.set_xlabel('X label') \n    ax1.set_ylabel('Y label')\n    ax1.set_zlabel('Z label')\n    # print(\"obs=\")\n    # print(could_plt)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "r3d_count_length",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def r3d_count_length(path,paths,i,j,path_lengths):\n    path_cost=0\n    expert_path_cost=0\n    expert_path=paths[i][j][:path_lengths[i][j]]\n    for k in range (0,len(path)-1):\n        path_cost=path_cost+((path[k+1][0]-path[k][0])**2+(path[k+1][1]-path[k][1])**2+(path[k+1][2]-path[k][2])**2)**0.5\n    for m in range (0,path_lengths[i][j]-1):\n        expert_path_cost=expert_path_cost+((expert_path[m+1][0]-expert_path[m][0])**2+(expert_path[m+1][1]-expert_path[m][1])**2+(expert_path[m+1][2]-expert_path[m][2])**2)**0.5\n        # paths[i][j][:path_lengths[i][j]][:,0]\n    rate=path_cost/expert_path_cost",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "IsInCollision",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def IsInCollision(x,idx): \n\tcf=False\n\tx=(x+bias)*scale_para\n\tif isinstance(x, torch.Tensor):\n\t\tx=x.detach().numpy()\n\tfx=np.floor(x).astype(int)\n\tcx=np.ceil(x).astype(int)\n\tif fx[0]>=scale_para*40:\n\t\tfx[0]=scale_para*40-1\n\tif fx[1]>=scale_para*40:",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "steerT",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def steerTo (start, end, idx):\n\tDISCRETIZATION_STEP=0.01\n\tdists=np.zeros(3,dtype=np.float32)\n\tfor i in range(0,3): \n\t\tdists[i] = end[i] - start[i]\n\tdistTotal = 0.0\n\tfor i in range(0,3): \n\t\tdistTotal =distTotal+ dists[i]*dists[i]\n\tdistTotal = math.sqrt(distTotal)\n\tif distTotal>0:",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "feasibility_check",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def feasibility_check(path,idx):\n\tfor i in range(0,len(path)-1):\n\t\tind=steerTo(path[i],path[i+1],idx)\n\t\tif ind==0:\n\t\t\treturn 0\n\treturn 1\n# checks the feasibility of path nodes only\ndef collision_check(path,idx):\n\tfor i in range(0,len(path)):\n\t\tif IsInCollision(path[i],idx):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "collision_check",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def collision_check(path,idx):\n\tfor i in range(0,len(path)):\n\t\tif IsInCollision(path[i],idx):\n\t\t\treturn 0\n\treturn 1\ndef to_var(x, volatile=False):\n\tif torch.cuda.is_available():\n\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,dataset,targets,seq,bs):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "to_var",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def to_var(x, volatile=False):\n\tif torch.cuda.is_available():\n\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,dataset,targets,seq,bs):\n\tbi=np.zeros((bs,18),dtype=np.float32)\n\tbt=np.zeros((bs,2),dtype=np.float32)\n\tk=0\t\n\tfor b in range(i,i+bs):\n\t\tbi[k]=dataset[seq[i]].flatten()",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "get_input",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def get_input(i,dataset,targets,seq,bs):\n\tbi=np.zeros((bs,18),dtype=np.float32)\n\tbt=np.zeros((bs,2),dtype=np.float32)\n\tk=0\t\n\tfor b in range(i,i+bs):\n\t\tbi[k]=dataset[seq[i]].flatten()\n\t\tbt[k]=targets[seq[i]].flatten()\n\t\tk=k+1\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)\ndef is_reaching_target(start1,start2):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "is_reaching_target",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def is_reaching_target(start1,start2):\n\ts1=np.zeros(2,dtype=np.float32)\n\ts1[0]=start1[0]\n\ts1[1]=start1[1]\n\ts2=np.zeros(2,dtype=np.float32)\n\ts2[0]=start2[0]\n\ts2[1]=start2[1]\n\tfor i in range(0,2):\n\t\tif abs(s1[i]-s2[i]) > 1.0: \n\t\t\treturn False",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "lvc",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def lvc(path,idx):\n\tfor i in range(0,len(path)-1):\n\t\tfor j in range(len(path)-1,i+1,-1):\n\t\t\tind=0\n\t\t\tind=steerTo(path[i],path[j],idx)\n\t\t\tif ind==1:\n\t\t\t\tpc=[]\n\t\t\t\tfor k in range(0,i+1):\n\t\t\t\t\tpc.append(path[k])\n\t\t\t\tfor k in range(j,len(path)):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "replan_path",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def replan_path(mlp,p,g,idx,obs):\n\tstep=0\n\titeration_replan=0\n\tpath=[]\n\tpath.append(p[0])\n\tfor i in range(1,len(p)-1):\n\t\tif not IsInCollision(p[i],idx):   #cut the collision point\n\t\t\tpath.append(p[i])\n\tpath.append(g)\t\t\t\n\tnew_path=[]",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "max_out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def max_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm):\n\tmax_possibility_theta, max_index_theta = torch.max(out_orient_theta_softm, dim=-1)\n\tmax_possibility_phi, max_index_phi = torch.max(out_orient_phi_softm, dim=-1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle #for multi-dimension out_orient_softm\n\t#out_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\t#out_angle_max = torch.from_numpy(out_angle_max).float().cuda()",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "rep_out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def rep_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm,rep_stuck_flag):\n\tN=1+rep_stuck_flag*args.Sparse_index #Find the element ranked rep_suck_flag+1\n\t# start_time = time.time()\n\tprob_matrix = out_orient_theta_softm[:, None] * out_orient_phi_softm[None, :]\n\tvalues_all, indices_all = torch.topk(prob_matrix.view(-1), N) #the first one is 0\n\t# nth_value = values[N-1]  \n\tnth_index = indices_all[N-1] #Because the index starts from 0\n\tnth_index_theta, nth_index_phi = nth_index // out_orient_phi_softm.size(0), nth_index % out_orient_phi_softm.size(0)\n\t# end_time = time.time()\n\t# value_theta, indices_theta = torch.topk(out_orient_theta_softm,rep_stuck_flag+1)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "Range_Limit",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def Range_Limit(point,out_range):\n\tcount_flag=0\n\tlimit=20\n\tfor i in range (0,3):\n\t\tif point[i]>limit:\n\t\t\tpoint[i]=limit\t\n\t\t\tcount_flag=1\n\t\t\tprint(\"!!!!!!!!!!!!!!!!!!!!!!!!!out of range!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n\t\tif point[i]<-limit:\n\t\t\tpoint[i]=-limit",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "Input_to_output_point",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def Input_to_output_point(mlp,input,num_sector_theta,num_sector_phi,out_range):\n\tout_norm, out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t\t  out_orient_theta_softm, out_orient_phi_softm=mlp(input)\n\tout_angle_theta_max,out_angle_phi_max=max_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm)\n\tout_norm=out_norm.data.cpu()\n\tout_angle_theta_max=out_angle_theta_max.data.cpu()\n\tout_angle_phi_max=out_angle_phi_max.data.cpu()\n\toutput_point=angle_norm_to_coordinate(out_norm,out_angle_theta_max,out_angle_phi_max,input)\n\toutput_point,out_range=Range_Limit(output_point,out_range)\n\treturn output_point,out_range",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "Re_Input_to_output_point",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def Re_Input_to_output_point(mlp,input,num_sector_theta,num_sector_phi,rep_stuck_flag_forward,out_range):\n\tout_norm, out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t\t  out_orient_theta_softm, out_orient_phi_softm=mlp(input)\n\tout_angle_theta_rep,out_angle_phi_rep=rep_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm,\\\n\t\t\t\t  rep_stuck_flag_forward)\n\tout_norm=0.51*(out_norm)+0.49*(out_norm)*math.sin(((rep_stuck_flag_forward/args.stuck_search_time)*180+90)/360*2*math.pi)\n\tout_norm=out_norm.data.cpu()\n\tout_angle_theta_rep=out_angle_theta_rep.data.cpu()\n\tout_angle_phi_rep=out_angle_phi_rep.data.cpu()\n\t# gl_orient_norm2[1]=0.51*(gl_orient_norm2[1])+0.49*(gl_orient_norm2[1])*math.sin((bias_angle_backward+90)/360*2*math.pi)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "def main(args):\n\t# Load trained model for path generation\n\tmlp = MLP_3D(args.input_size,args.num_sector_theta,args.num_sector_phi,args.dropout_p)\n\tencoder=AE.Encoder_CNN_3D(int(scale_para*40),args.dropout_p)\n\tmlp.eval()\n\tencoder.eval()\n\tmlp.load_state_dict(torch.load(args.MLP_path))\n\tencoder.load_state_dict(torch.load(args.CNN_path))\n\tif torch.cuda.is_available():\n\t\tmlp.cuda()",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\ttheta",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[60] + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[61]+ torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[62] + torch.cos(theta) * out_norm\t\n\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tphi",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[60] + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[61]+ torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[62] + torch.cos(theta) * out_norm\t\n\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\tnext_point[1]=last_point[1]+math.sin(orient_norm[0]/360*2*math.pi)*orient_norm[1]",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tx",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tx = bi[60] + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[61]+ torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[62] + torch.cos(theta) * out_norm\t\n\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\tnext_point[1]=last_point[1]+math.sin(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\treturn next_point",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\ty",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\ty = bi[61]+ torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[62] + torch.cos(theta) * out_norm\t\n\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\tnext_point[1]=last_point[1]+math.sin(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\treturn next_point\ndef r3d_plot_path(fp,path,size_start_end,marker_start,color,plot_color_count,marker_end,size_generate,paths,path_lengths,size_act,i,j,ax1):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tz",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tz = bi[62] + torch.cos(theta) * out_norm\t\n\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\tnext_point[1]=last_point[1]+math.sin(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\treturn next_point\ndef r3d_plot_path(fp,path,size_start_end,marker_start,color,plot_color_count,marker_end,size_generate,paths,path_lengths,size_act,i,j,ax1):\n\tprint(path)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tpredict_point",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tpredict_point = torch.cat((x, y, z)) \n\treturn predict_point\ndef orient_norm_to_coordinate(orient_norm,last_point):\n\tnext_point=torch.tensor([0.0,0.0])\n\tnext_point[0]=last_point[0]+math.cos(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\tnext_point[1]=last_point[1]+math.sin(orient_norm[0]/360*2*math.pi)*orient_norm[1]\n\treturn next_point\ndef r3d_plot_path(fp,path,size_start_end,marker_start,color,plot_color_count,marker_end,size_generate,paths,path_lengths,size_act,i,j,ax1):\n\tprint(path)\n\tif fp==1: #feasible path without replan",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\tdists[i]",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\tdists[i] = end[i] - start[i]\n\tdistTotal = 0.0\n\tfor i in range(0,3): \n\t\tdistTotal =distTotal+ dists[i]*dists[i]\n\tdistTotal = math.sqrt(distTotal)\n\tif distTotal>0:\n\t\tincrementTotal = distTotal/DISCRETIZATION_STEP\n\t\tfor i in range(0,3): \n\t\t\tdists[i] =dists[i]/incrementTotal\n\t\tnumSegments = int(math.floor(incrementTotal))",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tdistTotal",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tdistTotal = 0.0\n\tfor i in range(0,3): \n\t\tdistTotal =distTotal+ dists[i]*dists[i]\n\tdistTotal = math.sqrt(distTotal)\n\tif distTotal>0:\n\t\tincrementTotal = distTotal/DISCRETIZATION_STEP\n\t\tfor i in range(0,3): \n\t\t\tdists[i] =dists[i]/incrementTotal\n\t\tnumSegments = int(math.floor(incrementTotal))\n\t\tstateCurr = np.zeros(3,dtype=np.float32)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tdistTotal",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tdistTotal = math.sqrt(distTotal)\n\tif distTotal>0:\n\t\tincrementTotal = distTotal/DISCRETIZATION_STEP\n\t\tfor i in range(0,3): \n\t\t\tdists[i] =dists[i]/incrementTotal\n\t\tnumSegments = int(math.floor(incrementTotal))\n\t\tstateCurr = np.zeros(3,dtype=np.float32)\n\t\tfor i in range(0,3): \n\t\t\tstateCurr[i] = start[i]\n\t\tfor i in range(0,numSegments):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\tincrementTotal",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\tincrementTotal = distTotal/DISCRETIZATION_STEP\n\t\tfor i in range(0,3): \n\t\t\tdists[i] =dists[i]/incrementTotal\n\t\tnumSegments = int(math.floor(incrementTotal))\n\t\tstateCurr = np.zeros(3,dtype=np.float32)\n\t\tfor i in range(0,3): \n\t\t\tstateCurr[i] = start[i]\n\t\tfor i in range(0,numSegments):\n\t\t\tif IsInCollision(stateCurr,idx):\n\t\t\t\treturn 0",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\tnumSegments",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\tnumSegments = int(math.floor(incrementTotal))\n\t\tstateCurr = np.zeros(3,dtype=np.float32)\n\t\tfor i in range(0,3): \n\t\t\tstateCurr[i] = start[i]\n\t\tfor i in range(0,numSegments):\n\t\t\tif IsInCollision(stateCurr,idx):\n\t\t\t\treturn 0\n\t\t\tfor j in range(0,3):\n\t\t\t\tstateCurr[j] = stateCurr[j]+dists[j]\n\t\tif IsInCollision(end,idx):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\tstateCurr",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\tstateCurr = np.zeros(3,dtype=np.float32)\n\t\tfor i in range(0,3): \n\t\t\tstateCurr[i] = start[i]\n\t\tfor i in range(0,numSegments):\n\t\t\tif IsInCollision(stateCurr,idx):\n\t\t\t\treturn 0\n\t\t\tfor j in range(0,3):\n\t\t\t\tstateCurr[j] = stateCurr[j]+dists[j]\n\t\tif IsInCollision(end,idx):\n\t\t\treturn 0",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tstateCurr[i]",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tstateCurr[i] = start[i]\n\t\tfor i in range(0,numSegments):\n\t\t\tif IsInCollision(stateCurr,idx):\n\t\t\t\treturn 0\n\t\t\tfor j in range(0,3):\n\t\t\t\tstateCurr[j] = stateCurr[j]+dists[j]\n\t\tif IsInCollision(end,idx):\n\t\t\treturn 0\n\treturn 1\n# checks the feasibility of entire path including the path edges",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tstateCurr[j]",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\t\tstateCurr[j] = stateCurr[j]+dists[j]\n\t\tif IsInCollision(end,idx):\n\t\t\treturn 0\n\treturn 1\n# checks the feasibility of entire path including the path edges\ndef feasibility_check(path,idx):\n\tfor i in range(0,len(path)-1):\n\t\tind=steerTo(path[i],path[i+1],idx)\n\t\tif ind==0:\n\t\t\treturn 0",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,dataset,targets,seq,bs):\n\tbi=np.zeros((bs,18),dtype=np.float32)\n\tbt=np.zeros((bs,2),dtype=np.float32)\n\tk=0\t\n\tfor b in range(i,i+bs):\n\t\tbi[k]=dataset[seq[i]].flatten()\n\t\tbt[k]=targets[seq[i]].flatten()\n\t\tk=k+1",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle #for multi-dimension out_orient_softm\n\t#out_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\t#out_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\t# for i in range(0,len(out_orient_softm)):\n\t# \tout_angle_max[i]=center_angle[max_index[i]]\n\t# out_angle_max=out_angle_max.unsqueeze(1)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle #for multi-dimension out_orient_softm\n\t#out_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\t#out_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\t# for i in range(0,len(out_orient_softm)):\n\t# \tout_angle_max[i]=center_angle[max_index[i]]\n\t# out_angle_max=out_angle_max.unsqueeze(1)\n\tout_angle_theta_max=center_angle_theta[max_index_theta] #for 1 dimension",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle #for multi-dimension out_orient_softm\n\t#out_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\t#out_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\t# for i in range(0,len(out_orient_softm)):\n\t# \tout_angle_max[i]=center_angle[max_index[i]]\n\t# out_angle_max=out_angle_max.unsqueeze(1)\n\tout_angle_theta_max=center_angle_theta[max_index_theta] #for 1 dimension\n\tout_angle_phi_max=center_angle_phi[max_index_phi] #for 1 dimension",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle #for multi-dimension out_orient_softm\n\t#out_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\t#out_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\t# for i in range(0,len(out_orient_softm)):\n\t# \tout_angle_max[i]=center_angle[max_index[i]]\n\t# out_angle_max=out_angle_max.unsqueeze(1)\n\tout_angle_theta_max=center_angle_theta[max_index_theta] #for 1 dimension\n\tout_angle_phi_max=center_angle_phi[max_index_phi] #for 1 dimension\n\t# # A model that considers all angle possibilities",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t#out_angle_max",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t#out_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\t# for i in range(0,len(out_orient_softm)):\n\t# \tout_angle_max[i]=center_angle[max_index[i]]\n\t# out_angle_max=out_angle_max.unsqueeze(1)\n\tout_angle_theta_max=center_angle_theta[max_index_theta] #for 1 dimension\n\tout_angle_phi_max=center_angle_phi[max_index_phi] #for 1 dimension\n\t# # A model that considers all angle possibilities\n\t# center_angle = center_angle.unsqueeze(0) #cuda\n\t# out_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\t# out_angle = torch.sum(out_angle, dim=-1) # (batch_size,)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tprob_matrix",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tprob_matrix = out_orient_theta_softm[:, None] * out_orient_phi_softm[None, :]\n\tvalues_all, indices_all = torch.topk(prob_matrix.view(-1), N) #the first one is 0\n\t# nth_value = values[N-1]  \n\tnth_index = indices_all[N-1] #Because the index starts from 0\n\tnth_index_theta, nth_index_phi = nth_index // out_orient_phi_softm.size(0), nth_index % out_orient_phi_softm.size(0)\n\t# end_time = time.time()\n\t# value_theta, indices_theta = torch.topk(out_orient_theta_softm,rep_stuck_flag+1)\n\t# value_phi, indices_phi = torch.topk(out_orient_phi_softm,rep_stuck_flag+1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #[0,pi]\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tnth_index",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tnth_index = indices_all[N-1] #Because the index starts from 0\n\tnth_index_theta, nth_index_phi = nth_index // out_orient_phi_softm.size(0), nth_index % out_orient_phi_softm.size(0)\n\t# end_time = time.time()\n\t# value_theta, indices_theta = torch.topk(out_orient_theta_softm,rep_stuck_flag+1)\n\t# value_phi, indices_phi = torch.topk(out_orient_phi_softm,rep_stuck_flag+1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #[0,pi]\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector #[-pi,pi]\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tout_angle_theta_rep=center_angle_theta[nth_index_theta] #for 1 dimension",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #[0,pi]\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector #[-pi,pi]\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tout_angle_theta_rep=center_angle_theta[nth_index_theta] #for 1 dimension\n\tout_angle_phi_rep=center_angle_phi[nth_index_phi] #for 1 dimension\n\treturn out_angle_theta_rep,out_angle_phi_rep\ndef Range_Limit(point,out_range):\n\tcount_flag=0\n\tlimit=20",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector #[-pi,pi]\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tout_angle_theta_rep=center_angle_theta[nth_index_theta] #for 1 dimension\n\tout_angle_phi_rep=center_angle_phi[nth_index_phi] #for 1 dimension\n\treturn out_angle_theta_rep,out_angle_phi_rep\ndef Range_Limit(point,out_range):\n\tcount_flag=0\n\tlimit=20\n\tfor i in range (0,3):",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector #[-pi,pi]\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tout_angle_theta_rep=center_angle_theta[nth_index_theta] #for 1 dimension\n\tout_angle_phi_rep=center_angle_phi[nth_index_phi] #for 1 dimension\n\treturn out_angle_theta_rep,out_angle_phi_rep\ndef Range_Limit(point,out_range):\n\tcount_flag=0\n\tlimit=20\n\tfor i in range (0,3):\n\t\tif point[i]>limit:",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tout_angle_theta_rep=center_angle_theta[nth_index_theta] #for 1 dimension\n\tout_angle_phi_rep=center_angle_phi[nth_index_phi] #for 1 dimension\n\treturn out_angle_theta_rep,out_angle_phi_rep\ndef Range_Limit(point,out_range):\n\tcount_flag=0\n\tlimit=20\n\tfor i in range (0,3):\n\t\tif point[i]>limit:\n\t\t\tpoint[i]=limit\t",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tmlp",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tmlp = MLP_3D(args.input_size,args.num_sector_theta,args.num_sector_phi,args.dropout_p)\n\tencoder=AE.Encoder_CNN_3D(int(scale_para*40),args.dropout_p)\n\tmlp.eval()\n\tencoder.eval()\n\tmlp.load_state_dict(torch.load(args.MLP_path))\n\tencoder.load_state_dict(torch.load(args.CNN_path))\n\tif torch.cuda.is_available():\n\t\tmlp.cuda()\n\t\tencoder.cuda()\n\twith torch.no_grad():",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\ttic",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\t\t\ttic = time.clock()\t\n\t\t\t\t\tout_range_forward_basic=0\n\t\t\t\t\tout_range_backward_basic=0\n\t\t\t\t\tstop_forward_basic=0\n\t\t\t\t\tstop_backward_basic=0\n\t\t\t\t\twhile target_reached==0 and step<50 :\n\t\t\t\t\t\tif stop_forward_basic==1 and stop_backward_basic==1:\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\tstep=step+1\n\t\t\t\t\t\tif tree==0:",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\ttoc",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\t\t\t\t\ttoc = time.clock()\n\t\t\t\t\t\t\tt=toc-tic\n\t\t\t\t\t\t\tet.append(t)\n\t\t\t\t\t\t\tfp=fp+1\t\t\t\t\n\t\t\t\t\t\t\t#change by z\n\t\t\t\t\t\t\tpath_plt_m=torch.stack(path)\n\t\t\t\t\t\t\tpath_plt=path_plt_m.detach().cpu().numpy()\n\t\t\t\t\t\t\t# print(\"path_test\")\n\t\t\t\t\t\t\t# print(path_plt)\n\t\t\t\t\t\t\tif args.Plot_flag:",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\t\t\t\t\ttoc",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\t\t\t\t\t\t\ttoc = time.clock()\n\t\t\t\t\t\t\t\t\tt=toc-tic\n\t\t\t\t\t\t\t\t\tet.append(t)\n\t\t\t\t\t\t\t\t\tfp=fp+1\n\t\t\t\t\t\t\t\t\t#change by z\n\t\t\t\t\t\t\t\t\tpath_plt_m=torch.stack(path)\t\n\t\t\t\t\t\t\t\t\tpath_plt=path_plt_m.detach().cpu().numpy()\n\t\t\t\t\t\t\t\t\tif args.Plot_flag:\n\t\t\t\t\t\t\t\t\t\tr3d_plot_path(2,path_plt,size_start_end,marker_start,color,color_flag,marker_end,size_generate,paths,path_lengths,size_act,i,j,ax1)\n\t\t\t\t\t\t\t\t\t\tcolor_flag=color_flag+1 ",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\t#np.set_printoptions(threshold",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\t#np.set_printoptions(threshold = 1e6)\t#\tshow all the element of matrix\t\n\t\t\t#print(\"obs_recover\")\n\t\t\t#print(obs_recover[i])\n\t\t\t# recover_obs=obs_recover[i].reshape(len(obs_recover[i])//2,2) \n\t\t\t#plt.scatter(recover_obs[:,0], recover_obs[:,1], s=5,c='red')\n\t\t\titeration_all.append(iteration_env)\n\t\t\ttot.append(et)\t\t\t\t\n\t\t\tpath_cost_all.append(path_cost_env)\n\t\t\texpert_cost_all.append(expert_cost_env)\t\n\t\t\t# with open('tot_'+str(i)+'.csv', 'w', newline='') as file:",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tdata",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tdata = np.array(tot[i])\t\n\t\t\tmean_value = np.mean(data)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of time:\", mean_value)\n\t\t\tvariance_value = np.var(data)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of time:\", variance_value)\n\t\t\tpath_len=np.array(path_cost_all[i])\t\n\t\t\tprint(\"path_len\",path_len)\n\t\t\tmean_value = np.mean(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of path:\", mean_value)\n\t\t\tvariance_value = np.var(path_len)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tmean_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tmean_value = np.mean(data)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of time:\", mean_value)\n\t\t\tvariance_value = np.var(data)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of time:\", variance_value)\n\t\t\tpath_len=np.array(path_cost_all[i])\t\n\t\t\tprint(\"path_len\",path_len)\n\t\t\tmean_value = np.mean(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of path:\", mean_value)\n\t\t\tvariance_value = np.var(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of path:\", variance_value)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tvariance_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tvariance_value = np.var(data)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of time:\", variance_value)\n\t\t\tpath_len=np.array(path_cost_all[i])\t\n\t\t\tprint(\"path_len\",path_len)\n\t\t\tmean_value = np.mean(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of path:\", mean_value)\n\t\t\tvariance_value = np.var(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of path:\", variance_value)\n\t\t\texpert_len=np.array(expert_cost_all[i])\t\n\t\t\tprint(\"expert_len\",expert_len)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tmean_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tmean_value = np.mean(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of path:\", mean_value)\n\t\t\tvariance_value = np.var(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of path:\", variance_value)\n\t\t\texpert_len=np.array(expert_cost_all[i])\t\n\t\t\tprint(\"expert_len\",expert_len)\n\t\t\tmean_value = np.mean(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of expert path:\", mean_value)\n\t\t\tvariance_value = np.var(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of expert path:\", variance_value)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tvariance_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tvariance_value = np.var(path_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of path:\", variance_value)\n\t\t\texpert_len=np.array(expert_cost_all[i])\t\n\t\t\tprint(\"expert_len\",expert_len)\n\t\t\tmean_value = np.mean(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of expert path:\", mean_value)\n\t\t\tvariance_value = np.var(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of expert path:\", variance_value)\n\t\t\titeration_count=np.array(iteration_all[i])\t\n\t\t\tprint(\"iteration_count\",iteration_count)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tmean_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tmean_value = np.mean(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"mean of expert path:\", mean_value)\n\t\t\tvariance_value = np.var(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of expert path:\", variance_value)\n\t\t\titeration_count=np.array(iteration_all[i])\t\n\t\t\tprint(\"iteration_count\",iteration_count)\n\t\t\tmean_value = np.mean(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_mean:\", mean_value)\n\t\t\tvariance_value = np.var(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_var:\", variance_value)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tvariance_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tvariance_value = np.var(expert_len)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"variance of expert path:\", variance_value)\n\t\t\titeration_count=np.array(iteration_all[i])\t\n\t\t\tprint(\"iteration_count\",iteration_count)\n\t\t\tmean_value = np.mean(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_mean:\", mean_value)\n\t\t\tvariance_value = np.var(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_var:\", variance_value)\n\t\tpickle.dump(tot, open(\"time_s2D_unseen_mlp.p\", \"wb\" ))\n\t\tprint(enviro_type)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tmean_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tmean_value = np.mean(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_mean:\", mean_value)\n\t\t\tvariance_value = np.var(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_var:\", variance_value)\n\t\tpickle.dump(tot, open(\"time_s2D_unseen_mlp.p\", \"wb\" ))\n\t\tprint(enviro_type)\n\t\tprint(\"infeasible_path_index1\")\n\t\tprint(infeasible_path_index1)\n\t\tprint(\"infeasible_path_index2\")\n\t\tprint(infeasible_path_index2)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\t\t\tvariance_value",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\t\t\tvariance_value = np.var(iteration_count)\n\t\t\tprint(\"environment:\",i+args.enviro_index_low,\"iteration_var:\", variance_value)\n\t\tpickle.dump(tot, open(\"time_s2D_unseen_mlp.p\", \"wb\" ))\n\t\tprint(enviro_type)\n\t\tprint(\"infeasible_path_index1\")\n\t\tprint(infeasible_path_index1)\n\t\tprint(\"infeasible_path_index2\")\n\t\tprint(infeasible_path_index2)\n\t\tprint(\"invalid_start_or_goal\")\n\t\tprint(invalid_start_or_goal)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\tparser = argparse.ArgumentParser()\n\tparser.add_argument('--model_path', type=str, default='./models/',help='path for saving trained models')\n\tparser.add_argument('--MLP_path', type=str, default='./models/',help='path for saving trained models')\n\tparser.add_argument('--CNN_path', type=str, default='./models/',help='path for saving trained models')\n\tparser.add_argument('--input_size', type=int , default=32, help='dimension of the input vector')\n\tparser.add_argument('--num_sector_theta', type=int , default=90, help='The number of sectors that divide the space and num_sector must be even number') \n\tparser.add_argument('--num_sector_phi', type=int , default=180, help='The number of sectors that divide the space and num_sector must be even number') \n\tparser.add_argument('--dropout_p', type=float , default=0.0, help='The probability of dropout')\n\tparser.add_argument('--Plot_flag', type=int , default=0)\n\tparser.add_argument('--enviro_index_low', type=int , default=2)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "ATOA.test",
        "description": "ATOA.test",
        "peekOfCode": "\targs = parser.parse_args()\n\tprint(args)\n\tmain(args)",
        "detail": "ATOA.test",
        "documentation": {}
    },
    {
        "label": "check_data_valid",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def check_data_valid(data_list):\n\tfor data in data_list:\n\t\tif torch.isnan(data).any():\n\t\t\tprint(\"DISCOVER NAN!\")\n\t\t\tprint(data_list)\n\t\t\tassert 0\n\t\tif torch.isinf(data).any():\n\t\t\tprint(\"DISCOVER INF!\")\n\t\t\tprint(data_list)\n\t\t\tassert 0",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "to_var",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def to_var(x, volatile=False):\n\tif torch.cuda.is_available():\n\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "get_input",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]\n\t\tbt=targets[i:]\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)\ndef get_input_orient(i,env_indices,targets,padded_targets_future_all,data,\\\n\t\t     classification_orient_theta_targets,classification_orient_phi_targets\\",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "get_input_orient",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def get_input_orient(i,env_indices,targets,padded_targets_future_all,data,\\\n\t\t     classification_orient_theta_targets,classification_orient_phi_targets\\\n\t\t\t,classification_norm_targets,batch_size):\n\tif i+batch_size<len(data):\n\t\tbi=data[i:i+batch_size]\n\t\tbt1=classification_norm_targets[i:i+batch_size]\n\t\tbt2_theta=classification_orient_theta_targets[i:i+batch_size]\t\n\t\tbt2_phi=classification_orient_phi_targets[i:i+batch_size]\n\t\tcurrent_point=bi[:,60:63]\n\t\ttarget_point=targets[i:i+batch_size]\t",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "norm_loss_2",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def norm_loss_2(tilde_x, x_c, x_points, k1, k2=1.0):\n    distance_tilde_x_xc = torch.norm(tilde_x - x_c, p=2)  #  ||tilde_x - x_c||_2\n    distance_sum = sum(torch.norm(x_points[i + 1] - x_points[i], p=2) for i in range(len(x_points) - 1))  #  Σ ||x_{i+1} - x_i||_2\n    delta = distance_tilde_x_xc / distance_sum  \n    alpha = k2 if delta > 1 else 0 \n    log_term = torch.log1p(torch.exp(-k1 * (delta - 1)))  # log(1 + exp(-k1 * (delta - 1)))\n    loss = log_term + alpha * (delta - 1)  # L_norm = log_term + alpha * (delta - 1)\n    return loss\ndef norm_loss_relu(x,distance_left):\n    epsilon = 1e-10",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "norm_loss_relu",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def norm_loss_relu(x,distance_left):\n    epsilon = 1e-10\n    distance_left = torch.clamp(distance_left, min=epsilon)\n    ratio = torch.clamp(x / distance_left,min=-5) - 1 #if x / distance_left too small, like -10, the exp(100) will become inf\n    scaled_ratio = -10 * ratio\n    return 0.5 * torch.log1p(torch.exp(scaled_ratio)) #log1p(x)=log(1+x)\ndef max_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm):\n\tmax_possibility_theta, max_index_theta = torch.max(out_orient_theta_softm, dim=-1)\n\tmax_possibility_phi, max_index_phi = torch.max(out_orient_phi_softm, dim=-1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "max_out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def max_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm):\n\tmax_possibility_theta, max_index_theta = torch.max(out_orient_theta_softm, dim=-1)\n\tmax_possibility_phi, max_index_phi = torch.max(out_orient_phi_softm, dim=-1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm,out_orient_phi_softm):\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "angle_norm_to_coordinate",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "f_DL2",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)\n# \tx = torch.unsqueeze(x, dim=0)\n# \tdistance_point_to_obstacle=torch.sqrt(torch.sum(torch.square(torch.sub(t,x)),dim=-1))\n# \tdistance_point_to_obstacle=f_DL(distance_point_to_obstacle,4)\n# \tdistance_point_to_obstacle=torch.sum(distance_point_to_obstacle,dim=0)\n# \tdistance_point_to_obstacle=torch.mean(distance_point_to_obstacle)\n# \treturn distance_point_to_obstacle",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Predict_point_to_GT_loss",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def Predict_point_to_GT_loss(targets_point_future_all_batch,predict_point):\n\tpredict_point_mid=torch.unsqueeze(predict_point, dim=1) #[batch,1,dimension]\n\tdistance_point_to_all_gt=torch.sqrt(torch.sum(torch.square(torch.sub(predict_point_mid,targets_point_future_all_batch)),dim=-1))#[batch,max_future_all_length]\n\tcheck_data_valid([distance_point_to_all_gt])\n\tdistance_point_to_gt,index_1=torch.min(distance_point_to_all_gt,dim=-1) #[batch]\n\tdistance_point_to_gt_mean=torch.mean(distance_point_to_gt)\n\t# assert 0\n\treturn distance_point_to_gt_mean\ndef Count_Distance_mid_points_loss(enviro_mask_set,boundary_points_set,boundary_lengths,predict_point,current_point,idx):  #it is for interpolation point and predicted point\n\t#!!!Please be aware not to use args.batch_size_train to create the dimensions of arrays, as errors may occur when the data is insufficient to fill args.batch_size_train.!!!",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Count_Distance_mid_points_loss",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def Count_Distance_mid_points_loss(enviro_mask_set,boundary_points_set,boundary_lengths,predict_point,current_point,idx):  #it is for interpolation point and predicted point\n\t#!!!Please be aware not to use args.batch_size_train to create the dimensions of arrays, as errors may occur when the data is insufficient to fill args.batch_size_train.!!!\n\t#idx:(batch_size_train); enviro_mask_set:(load_data_N,140,140);\tenviro_mask_set[idx]:(batch_size,140,140); \n \t#mask_total_point:[1,num,batch_size_train,2];boundary_points_set:(load_data_N,max_boundary_length,2)\n\tnum=args.interpolation_point_num #interpolation points: interpolation_point_num-1. when num=interpolation_point_num, it represent the predicted point\n\ttotal_point=torch.zeros((num,predict_point.shape[0],predict_point.shape[1]))\n\ttotal_point=total_point.cuda()\n\tfor i in range (0,num):\n\t\ttotal_point[i]=current_point+(predict_point-current_point)*(i+1)/num\n\ttotal_point = torch.unsqueeze(total_point, dim=0) #[1,num,batch_size,dimension]",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "loss_function",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def loss_function(enviro_mask_set,boundary_points_set,boundary_lengths,env_indices_batch,\\\n\t\t      out_norm,out_orient_theta_raw,out_orient_phi_raw,bt1,bt2_theta,bt2_phi,predict_point,current_point,targets_point_future_all_batch,distance_current_to_goal):\n\tk1=args.k1\n\tk2_theta=args.k2_theta\n\tk2_phi=args.k2_phi\n\tk3=args.k3\n\tk4=args.k4\n\tpp_to_gt_loss=Predict_point_to_GT_loss(targets_point_future_all_batch,predict_point)\n\t# print(\"current_point\")\n\t# print(current_point)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Error_function",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,Tout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,Tbt1,Tbt2_theta,Tbt2_phi,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal):\n\t# TDistance_point_loss=Count_Distance_loss(Tpredict_point,Tenv_indices_batch,Tobc)\n\tTline_to_obs_collision=Count_Distance_mid_points_loss(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tpredict_point,Tcurrent_point,Tenv_indices_batch)\n\t# Tk1=torch.tensor(1.0).cuda()\n\t# Tk2=torch.tensor(1.0).cuda()\n\t# Tk3=torch.tensor(0.001).cuda()\n\tTk1=args.Tk1\n\tTk2_theta=args.Tk2_theta\n\tTk2_phi=args.Tk2_phi\n\tTk3=args.Tk3",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "error_count",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def error_count(predict_point,target_point):\n\tPre_point_error=torch.square(torch.sub(predict_point,target_point))\n\tPre_point_error=torch.sqrt(torch.sum(Pre_point_error,dim=1)) \n\tPre_point_error=torch.mean(Pre_point_error)\n\treturn Pre_point_error\ndef Train(mlp,encoder,enviro_mask_set,boundary_points_set,boundary_lengths,env_indices,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets,optimizer,total_loss):\n\tencoder.train()\n\tmlp.train()\t\n\tloss = 0\n\t# print(\"args.batch_size_train\")",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Train",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def Train(mlp,encoder,enviro_mask_set,boundary_points_set,boundary_lengths,env_indices,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets,optimizer,total_loss):\n\tencoder.train()\n\tmlp.train()\t\n\tloss = 0\n\t# print(\"args.batch_size_train\")\n\t# print(args.batch_size_train)\n\tavg_loss=0\n\tavg_mse=0\n\tavg_cross_theta=0\n\tavg_cross_phi=0",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Test",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def Test(mlp,encoder,Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices,Ttargets,Tpadded_targets_future_all,Torient_dataset,Tclassification_orient_theta_targets,Tclassification_orient_phi_targets,Tclassification_norm_targets,Ttotal_error):\n\tmlp.eval()\n\tencoder.eval()\n\tTavg_error=0.0\n\tTavg_out_norm_error=0.0\n\tTavg_cross_error_theta=0.0\n\tTavg_cross_error_phi=0.0\n\tTavg_line_to_obs_collision=0.0\n\tTavg_Pre_point_error=0.0\n\tTavg_pp_to_gt_error=0",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "def main(args):\n\t# Create model directory\n\tif not os.path.exists(args.model_path):\n\t\tos.makedirs(args.model_path)\n\t# Build data loader\n\t#N=number of environments; NP=Number of Paths default:N=100,NP=4000\n\tenviro_mask_set,boundary_points_set,boundary_lengths,env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets\\\n\t\t= load_dataset_crossentropy(scale_para=args.scale_para,bias=args.bias,num_sector_theta=args.num_sector_theta,num_sector_phi=args.num_sector_phi,N=args.load_data_N,NP=args.load_data_NP,s=args.s,sp=args.sp) #type: numpy.ndarray N=10,NP=400\n\tprint(\"targets\",targets,targets.shape)\n\t# print(\"padded_targets_future_all\")",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]\n\t\tbt=targets[i:]\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Cross_loss_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "Cross_loss_theta = nn.CrossEntropyLoss()\nCross_loss_phi = nn.CrossEntropyLoss()\nCross_loss_theta_test = nn.CrossEntropyLoss()\nCross_loss_phi_test = nn.CrossEntropyLoss()\n# def new_norm_loss(x, a, b, c):\n#     sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n#     return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Cross_loss_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "Cross_loss_phi = nn.CrossEntropyLoss()\nCross_loss_theta_test = nn.CrossEntropyLoss()\nCross_loss_phi_test = nn.CrossEntropyLoss()\n# def new_norm_loss(x, a, b, c):\n#     sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n#     return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss) ",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Cross_loss_theta_test",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "Cross_loss_theta_test = nn.CrossEntropyLoss()\nCross_loss_phi_test = nn.CrossEntropyLoss()\n# def new_norm_loss(x, a, b, c):\n#     sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n#     return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss) \ndef norm_loss_2(tilde_x, x_c, x_points, k1, k2=1.0):",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "Cross_loss_phi_test",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "Cross_loss_phi_test = nn.CrossEntropyLoss()\n# def new_norm_loss(x, a, b, c):\n#     sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n#     return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss) \ndef norm_loss_2(tilde_x, x_c, x_points, k1, k2=1.0):\n    distance_tilde_x_xc = torch.norm(tilde_x - x_c, p=2)  #  ||tilde_x - x_c||_2",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)\n\tfor i in range(0,len(out_angle_max_phi)):",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tout_angle_max_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)\n\tfor i in range(0,len(out_angle_max_phi)):\n\t\tout_angle_max_phi[i]=center_angle_phi[max_index_phi[i]]\n\tout_angle_max_phi=out_angle_max_phi.unsqueeze(1)\n\treturn out_angle_max_theta,out_angle_max_phi\ndef out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm,out_orient_phi_softm):",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tout_angle_max_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)\n\tfor i in range(0,len(out_angle_max_phi)):\n\t\tout_angle_max_phi[i]=center_angle_phi[max_index_phi[i]]\n\tout_angle_max_phi=out_angle_max_phi.unsqueeze(1)\n\treturn out_angle_max_theta,out_angle_max_phi\ndef out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm,out_orient_phi_softm):\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tout_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tout_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tout_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tout_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\ttheta",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tphi",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tx",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) ",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\ty",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tz",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tpredict_point",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)\n# \tx = torch.unsqueeze(x, dim=0)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\ttotal_point",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\ttotal_point = torch.unsqueeze(total_point, dim=0) #[1,num,batch_size,dimension]\n\tcheck_data_valid([total_point])\n\tboundary_points=boundary_points_set[idx] #(batch_size,max_boundary_length,dimension)\n\tboundary_points=to_var(boundary_points)\n\tboundary_points=boundary_points.transpose(1,0) #(max_boundary_length,batch_size,dimension)\n\tboundary_points=torch.unsqueeze(boundary_points, dim=1) #(max_boundary_length,1,batch_size,dimension)\n\tcheck_data_valid([boundary_points])\n\tmask_total_point=torch.add(total_point,args.bias)*args.scale_para #mask_total_point:[1,num,batch_size_train,dimension] [1,5,6,3]\n\tcheck_data_valid([mask_total_point])\n\tmask_total_point_floor=torch.floor(mask_total_point).to(torch.long) #[1,num,batch_size_train,dimension]",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tsign_value",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tsign_value = 1 - 2 * sign_value\n\tcheck_data_valid([sign_value])\n\tsign_value=sign_value.transpose(0,1) #sign_value(num,batch_size)\n\t#boundary_points(max_boundary_length,1,batch_size,2) total_point[1,num,batch_size,2] #sign_value(num,batch_size)\n\tdistance_point_to_boundary_points=torch.sqrt(torch.sum(torch.square(torch.sub(boundary_points,total_point)),dim=-1)) #(max_boundary_length,num,batch_size)\n\tcheck_data_valid([distance_point_to_boundary_points])\n\tdistance_point_to_obstacle,to_obstacle_index=torch.min(distance_point_to_boundary_points,dim=0) #(num,batch_size)\n\t# print(\"distance_point_to_obstacle\")\n\t# print(distance_point_to_obstacle)\n\tcheck_data_valid([distance_point_to_obstacle])",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tloss",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tloss = 0\n\t# print(\"args.batch_size_train\")\n\t# print(args.batch_size_train)\n\tavg_loss=0\n\tavg_mse=0\n\tavg_cross_theta=0\n\tavg_cross_phi=0\n\tavg_point_error=0\n\tavg_line_to_obs_loss=0\n\tavg_pp_to_gt_loss=0",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\tbt1",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\tbt1 = torch.unsqueeze(bt1, dim=1) #from [batch_size] to [batch_size,1]\n\t\tbt2_theta=to_var(bt2_theta)\n\t\tbt2_phi=to_var(bt2_phi)\n\t\t# print(\"enviro_mask_set[env_indices_batch].unsqueeze(1)\",enviro_mask_set[env_indices_batch].unsqueeze(1).shape)\n\t\tzn=encoder(enviro_mask_set[env_indices_batch].unsqueeze(1))\n\t\t# print(\"zn\",zn.shape)\n\t\tmlp_in = torch.cat((zn,bi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\tout_norm, out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t\t  out_orient_theta_softm, out_orient_phi_softm= mlp(mlp_in)   #torch.Tensor+cuda\n\t\t# print(\"out_norm\",out_norm,out_norm.shape)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\tmlp_in",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\tmlp_in = torch.cat((zn,bi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\tout_norm, out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t\t  out_orient_theta_softm, out_orient_phi_softm= mlp(mlp_in)   #torch.Tensor+cuda\n\t\t# print(\"out_norm\",out_norm,out_norm.shape)\n\t\tcheck_data_valid([out_norm,out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t    out_orient_theta_softm,out_orient_phi_softm])\n\t\tout_angle_theta,out_angle_phi=out_softm_to_angle(args.num_sector_theta,args.num_sector_phi,out_orient_theta_softm,out_orient_phi_softm)\n\t\tpredict_point=angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi) #cuda\n\t\tcurrent_point=to_var(current_point)\n\t\tcheck_data_valid([out_angle_theta,out_angle_phi,predict_point,current_point])",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\tloss_all,out_norm_loss,loss_cross_theta,loss_cross_phi,line_to_obs_loss,pp_to_gt_loss",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\tloss_all,out_norm_loss,loss_cross_theta,loss_cross_phi,line_to_obs_loss,pp_to_gt_loss = loss_function(enviro_mask_set,boundary_points_set,boundary_lengths,env_indices_batch,\\\n\t\t\t\t\t\t\t   out_norm,out_orient_theta_raw,out_orient_phi_raw,bt1,bt2_theta,bt2_phi,predict_point,current_point,targets_point_future_all_batch,distance_current_to_goal) #1\n\t\tloss_all.backward()\n\t\toptimizer.step()\n\t\tpredict_point_cpu=predict_point.cpu()\n\t\tPre_point_error=error_count(predict_point_cpu,target_point)\n\t\tavg_loss=avg_loss+loss_all.data #change by z\n\t\tavg_out_norm_loss=avg_out_norm_loss+out_norm_loss.data #change by z\n\t\tavg_cross_theta=avg_cross_theta+loss_cross_theta.data #change by z\n\t\tavg_cross_phi=avg_cross_phi+loss_cross_phi.data #change by z",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\t\tTbt1",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\t\tTbt1 = torch.unsqueeze(Tbt1, dim=1) #from [batch_size_test] to [batch_size_test,1]\n\t\t\tTbt2_theta=to_var(Tbt2_theta)\n\t\t\tTbt2_phi=to_var(Tbt2_phi)\n\t\t\tTzn=encoder(Tenviro_mask_set[Tenv_indices_batch].unsqueeze(1))\n\t\t\tTmlp_in = torch.cat((Tzn,Tbi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t\tTout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,\\\n\t\t\t  Tout_orient_theta_softm, Tout_orient_phi_softm= mlp(Tmlp_in)   #torch.Tensor+cuda\n\t\t\t# Tout_angle=out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that considers all angle possibilities\n\t\t\tTout_angle_theta,Tout_angle_phi=max_out_softm_to_angle(args.num_sector_theta,args.num_sector_phi,Tout_orient_theta_softm, Tout_orient_phi_softm) # A model that take the most probable angle\n\t\t\tTpredict_point=angle_norm_to_coordinate(Tout_norm,Tout_angle_theta,Tout_angle_phi,Tbi) #cuda",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\t\tTmlp_in",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\t\tTmlp_in = torch.cat((Tzn,Tbi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t\tTout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,\\\n\t\t\t  Tout_orient_theta_softm, Tout_orient_phi_softm= mlp(Tmlp_in)   #torch.Tensor+cuda\n\t\t\t# Tout_angle=out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that considers all angle possibilities\n\t\t\tTout_angle_theta,Tout_angle_phi=max_out_softm_to_angle(args.num_sector_theta,args.num_sector_phi,Tout_orient_theta_softm, Tout_orient_phi_softm) # A model that take the most probable angle\n\t\t\tTpredict_point=angle_norm_to_coordinate(Tout_norm,Tout_angle_theta,Tout_angle_phi,Tbi) #cuda\n\t\t\tTcurrent_point=to_var(Tcurrent_point)\n\t\t\tTerror_all,Tout_norm_error,Tcross_error_theta,Tcross_error_phi,Tline_to_obs_collision,Tpp_to_gt_error= Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,Tout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,Tbt1,Tbt2_theta,Tbt2_phi,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal) #1\n\t\t\tTavg_error=Tavg_error+Terror_all.data #change by z\n\t\t\tTavg_out_norm_error=Tavg_out_norm_error+Tout_norm_error.data #change by z",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tmlp",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tmlp = MLP_3D(args.input_size,args.num_sector_theta,args.num_sector_phi,args.dropout_p_MLP)\n\tencoder=AE.Encoder_CNN_3D(int(args.scale_para*40),args.dropout_p_CNN)\n\tif args.preload_all:\n\t\tmlp.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/MLP_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_mlp_model\")\n\t\tencoder.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/CNN_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_encoder_model\")\n\telif args.preload_encoder:\n\t\tencoder.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/CNN_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_encoder_model\")",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\toptimizer",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\toptimizer = torch.optim.Adam([\n\t\t\t{'params': encoder.parameters(), 'lr': args.learning_rate_encoder},  #The learning rate set for the encoder\n\t\t\t{'params': mlp.parameters(), 'lr': args.learning_rate_planner}       #Learning rate set for MLP\n\t\t])\n\telse:\n\t\toptimizer = torch.optim.Adam(list(encoder.parameters())+list(mlp.parameters()),lr=args.learning_rate_together) \n\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t\toptimizer",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t\toptimizer = torch.optim.Adam(list(encoder.parameters())+list(mlp.parameters()),lr=args.learning_rate_together) \n\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]\n\tUTtotal_error=[]\n\tsm=50 # start saving models after 100 epochs\n\tfor epoch in range(args.num_epochs):\n\t\tprint (\"epoch\" + str(epoch)+\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") #change by z\n\t\tavg_loss=0.0",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\t#optimizer",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]\n\tUTtotal_error=[]\n\tsm=50 # start saving models after 100 epochs\n\tfor epoch in range(args.num_epochs):\n\t\tprint (\"epoch\" + str(epoch)+\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") #change by z\n\t\tavg_loss=0.0\n\t\tavg_mse=0.0",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\tparser = argparse.ArgumentParser()\t\n\tparser.add_argument('--model_path', type=str, default='./models/crossentropy/test',help='path for saving trained models')\n\t# Model parameters\n\tparser.add_argument('--input_size', type=int , default=32, help='dimension of the input vector')\n\t# Mask map parameters\n\tparser.add_argument('--scale_para', type=float , default=4, help='the scale of mask map')\n\tparser.add_argument('--bias', type=float , default=20.0, help='the bias of mask map')\n#____________________________\n\t# the parameters under this line need to be adjust\n\tparser.add_argument('--num_epochs', type=int, default=4000)",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "ATOA.train",
        "description": "ATOA.train",
        "peekOfCode": "\targs = parser.parse_args()\n\tprint(args)\n\tmain(args)\n# it is for orientation version",
        "detail": "ATOA.train",
        "documentation": {}
    },
    {
        "label": "check_data_valid",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def check_data_valid(data_list):\n\tfor data in data_list:\n\t\tif torch.isnan(data).any():\n\t\t\tprint(\"DISCOVER NAN!\")\n\t\t\tprint(data_list)\n\t\t\tassert 0\n\t\tif torch.isinf(data).any():\n\t\t\tprint(\"DISCOVER INF!\")\n\t\t\tprint(data_list)\n\t\t\tassert 0",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "to_var",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def to_var(x, volatile=False):\n\tif torch.cuda.is_available():\n\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "get_input",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]\n\t\tbt=targets[i:]\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)\ndef get_input_orient(i,env_indices,targets,padded_targets_future_all,data,classification_orient_targets,classification_norm_targets,bs):\n\tif i+bs<len(data):",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "get_input_orient",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def get_input_orient(i,env_indices,targets,padded_targets_future_all,data,classification_orient_targets,classification_norm_targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt1=classification_norm_targets[i:i+bs]\n\t\tbt2=classification_orient_targets[i:i+bs]\t\n\t\tcurrent_point=bi[:,28:30]\n\t\ttarget_point=targets[i:i+bs]\t\n\t\ttargets_point_future_all_batch=padded_targets_future_all[i:i+bs]\n\t\tenv_indices_batch=env_indices[i:i+bs]\n\telse:",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "new_norm_loss",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播\ndef norm_loss_relu(x,distance_left):\n    epsilon = 1e-10\n    distance_left = torch.clamp(distance_left, min=epsilon)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "norm_loss_relu",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def norm_loss_relu(x,distance_left):\n    epsilon = 1e-10\n    distance_left = torch.clamp(distance_left, min=epsilon)\n    ratio = torch.clamp(x / distance_left,min=-5) - 1 #if x / distance_left too small, like -10, the exp(100) will become inf\n    scaled_ratio = -10 * ratio\n    return 0.5 * torch.log1p(torch.exp(scaled_ratio)) #log1p(x)=log(1+x)\ndef max_out_softm_to_angle(num_sector,out_orient_softm):\n\tmax_possibility, max_index = torch.max(out_orient_softm, dim=-1)\n\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "max_out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def max_out_softm_to_angle(num_sector,out_orient_softm):\n\tmax_possibility, max_index = torch.max(out_orient_softm, dim=-1)\n\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\tout_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\tfor i in range(0,len(out_orient_softm)):\n\t\tout_angle_max[i]=center_angle[max_index[i]]\n\tout_angle_max=out_angle_max.unsqueeze(1)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def out_softm_to_angle(num_sector,out_orient_softm):\n\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle\ndef angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "angle_norm_to_coordinate",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm\n\ty=bi[:,29].unsqueeze(1)+torch.sin(out_angle/360*2*math.pi)*out_norm\n\tpredict_point = torch.cat((x, y), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) ",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "f_DL2",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)\n# \tx = torch.unsqueeze(x, dim=0)\n# \tdistance_point_to_obstacle=torch.sqrt(torch.sum(torch.square(torch.sub(t,x)),dim=-1))\n# \tdistance_point_to_obstacle=f_DL(distance_point_to_obstacle,4)\n# \tdistance_point_to_obstacle=torch.sum(distance_point_to_obstacle,dim=0)\n# \tdistance_point_to_obstacle=torch.mean(distance_point_to_obstacle)\n# \treturn distance_point_to_obstacle",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Predict_point_to_GT_loss",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def Predict_point_to_GT_loss(targets_point_future_all_batch,predict_point):\n\tpredict_point_mid=torch.unsqueeze(predict_point, dim=1) #[batch,1,dimension]\n\tdistance_point_to_all_gt=torch.sqrt(torch.sum(torch.square(torch.sub(predict_point_mid,targets_point_future_all_batch)),dim=-1))#[batch,max_future_all_length]\n\tcheck_data_valid([distance_point_to_all_gt])\n\tdistance_point_to_gt,index_1=torch.min(distance_point_to_all_gt,dim=-1) #[batch]\n\tdistance_point_to_gt_mean=torch.mean(distance_point_to_gt)\n\t# print(\"targets_point_future_all_batch\")\n\t# print(targets_point_future_all_batch)\n\t# print(targets_point_future_all_batch.shape)\n\t# print(\"predict_point\")",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Count_Distance_mid_points_loss",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def Count_Distance_mid_points_loss(enviro_mask_set,boundary_points_set,boundary_lengths,predict_point,current_point,idx):  #it is for interpolation point and predicted point\n\t#!!!Please be aware not to use args.batch_size_train to create the dimensions of arrays, as errors may occur when the data is insufficient to fill args.batch_size_train.!!!\n\t#idx:(batch_size_train); enviro_mask_set:(load_data_N,140,140);\tenviro_mask_set[idx]:(batch_size,140,140); \n \t#mask_total_point:[1,num,batch_size_train,2];boundary_points_set:(load_data_N,max_boundary_length,2)\n\tnum=args.interpolation_point_num #interpolation points: interpolation_point_num-1. when num=interpolation_point_num, it represent the predicted point\n\ttotal_point=torch.zeros((num,predict_point.shape[0],predict_point.shape[1]))\n\ttotal_point=total_point.cuda()\n\tfor i in range (0,num):\n\t\ttotal_point[i]=current_point+(predict_point-current_point)*(i+1)/num\n\ttotal_point = torch.unsqueeze(total_point, dim=0) #[1,num,batch_size,2]",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "loss_function",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def loss_function(enviro_mask_set,boundary_points_set,boundary_lengths,env_indices_batch,\\\n\t\t      out_norm,out_orient_raw,bt1,bt2,predict_point,current_point,targets_point_future_all_batch,distance_current_to_goal):\n\tk1=args.k1\n\tk2=args.k2\n\tk3=args.k3\n\tk4=args.k4\n\tpp_to_gt_loss=Predict_point_to_GT_loss(targets_point_future_all_batch,predict_point)\n\t# print(\"current_point\")\n\t# print(current_point)\n\t# print(current_point.shape)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Error_function",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,\\\n\t\t   Tout_norm, Tout_orient_raw,Tbt1,Tbt2,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal):\n\t# Tk1=torch.tensor(1.0).cuda()\n\t# Tk2=torch.tensor(1.0).cuda()\n\t# Tk3=torch.tensor(0.001).cuda()\n\tTk1=args.Tk1\n\tTk2=args.Tk2\n\tTk3=args.Tk3\n\tTk4=args.Tk4\n\tTtargets_point_future_all_batch=torch.from_numpy(Ttargets_point_future_all_batch) #class torch.Tensor",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "error_count",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def error_count(predict_point,target_point):\n\tPre_point_error=torch.square(torch.sub(predict_point,target_point))\n\tPre_point_error=torch.sqrt(torch.sum(Pre_point_error,dim=1)) \n\tPre_point_error=torch.mean(Pre_point_error)\n\treturn Pre_point_error\ndef Train(mlp,encoder,enviro_mask_set,boundary_points_set,boundary_lengths,env_indices,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets,optimizer,total_loss):\n\tencoder.train()\n\tmlp.train()\t\n\tloss = 0\n\t# print(\"args.batch_size_train\")",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Train",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def Train(mlp,encoder,enviro_mask_set,boundary_points_set,boundary_lengths,env_indices,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets,optimizer,total_loss):\n\tencoder.train()\n\tmlp.train()\t\n\tloss = 0\n\t# print(\"args.batch_size_train\")\n\t# print(args.batch_size_train)\n\tavg_loss=0\n\tavg_mse=0\n\tavg_cross=0\n\tavg_point_error=0",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Test",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def Test(mlp,encoder,Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices,Ttargets,Tpadded_targets_future_all,Torient_dataset,Tclassification_orient_targets,Tclassification_norm_targets,Ttotal_error):\n\tmlp.eval()\n\tencoder.eval()\n\tTavg_error=0.0\n\tTavg_out_norm_error=0.0\n\tTavg_cross_error=0.0\n\tTavg_line_to_obs_collision=0.0\n\tTavg_Pre_point_error=0.0\n\tTavg_pp_to_gt_error=0\n\tTboundary_points_set=torch.from_numpy(Tboundary_points_set) #class torch.Tensor",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "def main(args):\n\t# Create model directory\n\tif not os.path.exists(args.model_path):\n\t\tos.makedirs(args.model_path)\n\t# Build data loader\n\t#N=number of environments; NP=Number of Paths default:N=100,NP=4000\n\tenviro_mask_set,boundary_points_set,boundary_lengths,env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_targets,classification_norm_targets= load_dataset_crossentropy(scale_para=args.scale_para,bias=args.bias,num_sector=args.num_sector,N=args.load_data_N,NP=args.load_data_NP) #type: numpy.ndarray N=10,NP=400\n\t# assert 0\n\tprint(\"len(targets)\",len(targets))\n\tprint(\"len(classification_orient_targets)\",classification_orient_targets,len(classification_orient_targets))",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]\n\t\tbt=targets[i:]\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Cross_loss",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "Cross_loss = nn.CrossEntropyLoss()\nCross_loss_test = nn.CrossEntropyLoss()\ndef new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播\ndef norm_loss_relu(x,distance_left):",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "Cross_loss_test",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "Cross_loss_test = nn.CrossEntropyLoss()\ndef new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播\ndef norm_loss_relu(x,distance_left):\n    epsilon = 1e-10",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\tout_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\tfor i in range(0,len(out_orient_softm)):\n\t\tout_angle_max[i]=center_angle[max_index[i]]\n\tout_angle_max=out_angle_max.unsqueeze(1)\n\t# A model that considers all angle possibilities\n\tcenter_angle = center_angle.unsqueeze(0) #cuda",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max=np.zeros((len(out_orient_softm)),dtype=np.float32)\n\tout_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\tfor i in range(0,len(out_orient_softm)):\n\t\tout_angle_max[i]=center_angle[max_index[i]]\n\tout_angle_max=out_angle_max.unsqueeze(1)\n\t# A model that considers all angle possibilities\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_max",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tout_angle_max = torch.from_numpy(out_angle_max).float().cuda()\n\tfor i in range(0,len(out_orient_softm)):\n\t\tout_angle_max[i]=center_angle[max_index[i]]\n\tout_angle_max=out_angle_max.unsqueeze(1)\n\t# A model that considers all angle possibilities\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle_max",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle_max\ndef out_softm_to_angle(num_sector,out_orient_softm):\n\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tout_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle_max\ndef out_softm_to_angle(num_sector,out_orient_softm):\n\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tout_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle_max\ndef out_softm_to_angle(num_sector,out_orient_softm):\n\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tcenter_angle = np.linspace(-180+360/args.num_sector/2, 180-360/args.num_sector/2, args.num_sector) #center_angle for each sector\n\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle\ndef angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm\n\ty=bi[:,29].unsqueeze(1)+torch.sin(out_angle/360*2*math.pi)*out_norm",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tcenter_angle = torch.from_numpy(center_angle).float().cuda()\n\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle\ndef angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm\n\ty=bi[:,29].unsqueeze(1)+torch.sin(out_angle/360*2*math.pi)*out_norm\n\tpredict_point = torch.cat((x, y), dim=1)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tcenter_angle = center_angle.unsqueeze(0) #cuda\n\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle\ndef angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm\n\ty=bi[:,29].unsqueeze(1)+torch.sin(out_angle/360*2*math.pi)*out_norm\n\tpredict_point = torch.cat((x, y), dim=1)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tout_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tout_angle = torch.mul(center_angle, out_orient_softm) # (batch_size,num_sector)\n\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle\ndef angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm\n\ty=bi[:,29].unsqueeze(1)+torch.sin(out_angle/360*2*math.pi)*out_norm\n\tpredict_point = torch.cat((x, y), dim=1)\n\treturn predict_point",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tout_angle",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tout_angle = torch.sum(out_angle, dim=-1) # (batch_size,)\n\tout_angle=out_angle.unsqueeze(1) #add a dimension\n\treturn out_angle\ndef angle_norm_to_coordinate(out_norm,out_angle,bi):\n\tx=bi[:,28].unsqueeze(1)+torch.cos(out_angle/360*2*math.pi)*out_norm\n\ty=bi[:,29].unsqueeze(1)+torch.sin(out_angle/360*2*math.pi)*out_norm\n\tpredict_point = torch.cat((x, y), dim=1)\n\treturn predict_point\n# def f_DL(x, k):",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tpredict_point",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tpredict_point = torch.cat((x, y), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)\n# \tx = torch.unsqueeze(x, dim=0)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\ttotal_point",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\ttotal_point = torch.unsqueeze(total_point, dim=0) #[1,num,batch_size,2]\n\t# print(\"total_point\")\n\t# print(total_point)\n\tcheck_data_valid([total_point])\n\tboundary_points=boundary_points_set[idx] #(batch_size,max_boundary_length,2)\n\tboundary_points=to_var(boundary_points)\n\tboundary_points=boundary_points.transpose(1,0) #(max_boundary_length,batch_size,2)\n\tboundary_points=torch.unsqueeze(boundary_points, dim=1) #(max_boundary_length,1,batch_size,2)\n\t# print(\"boundary_points\")\n\t# print(boundary_points)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tloss",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tloss = 0\n\t# print(\"args.batch_size_train\")\n\t# print(args.batch_size_train)\n\tavg_loss=0\n\tavg_mse=0\n\tavg_cross=0\n\tavg_point_error=0\n\tavg_line_to_obs_loss=0\n\tavg_pp_to_gt_loss=0\n\tavg_out_norm_loss=0",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\tbt1",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\tbt1 = torch.unsqueeze(bt1, dim=1) #from [batch_size] to [batch_size,1]\n\t\tbt2=to_var(bt2)\n\t\t# print(\"env_indices_batch\")\n\t\t# print(env_indices_batch)    \n\t\t# print(env_indices_batch.shape) \n\t\t# print(\"bi\")\n\t\t# print(bi)    \n\t\t# print(bi.shape)   \t\t\n\t\t# print(\"bt1\")\n\t\t# print(bt1)    ",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\tmlp_in",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\tmlp_in = torch.cat((zn,bi[:,28:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t# print(\"zn\")\n\t\t# print(zn)\n\t\t# print(zn.shape)\n\t\t# print(\"bi\")\n\t\t# print(bi)\n\t\t# print(bi.shape)\n\t\t# print(\"mlp_in\")\n\t\t# print(mlp_in)\n\t\t# print(mlp_in.shape)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\tloss_all,out_norm_loss,loss_cross,line_to_obs_loss,pp_to_gt_loss",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\tloss_all,out_norm_loss,loss_cross,line_to_obs_loss,pp_to_gt_loss = loss_function(enviro_mask_set,boundary_points_set,boundary_lengths,env_indices_batch,\\\n\t\t\t\t\t\t\t   out_norm,out_orient_raw,bt1,bt2,predict_point,current_point,targets_point_future_all_batch,distance_current_to_goal) #1\n\t\tloss_all.backward()\n\t\toptimizer.step()\n\t\tpredict_point_cpu=predict_point.cpu()\n\t\tPre_point_error=error_count(predict_point_cpu,target_point)\n\t\tavg_loss=avg_loss+loss_all.data #change by z\n\t\tavg_out_norm_loss=avg_out_norm_loss+out_norm_loss.data #change by z\n\t\tavg_cross=avg_cross+loss_cross.data #change by z\n\t\tavg_line_to_obs_loss=avg_line_to_obs_loss+line_to_obs_loss",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\t\tTbt1",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\t\tTbt1 = torch.unsqueeze(Tbt1, dim=1) #from [batch_size_test] to [batch_size_test,1]\n\t\t\tTbt2=to_var(Tbt2)\n\t\t\tTzn=encoder(Tenviro_mask_set[Tenv_indices_batch].unsqueeze(1))\n\t\t\tTmlp_in = torch.cat((Tzn,Tbi[:,28:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t\tTout_norm, Tout_orient_raw, Tout_orient_softm = mlp(Tmlp_in)   #([batch_size_test, 2])\n\t\t\t#Tout_angle=out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that considers all angle possibilities\n\t\t\tTout_angle=max_out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that take the most probable angle\n\t\t\tTpredict_point=angle_norm_to_coordinate(Tout_norm,Tout_angle,Tbi)\n\t\t\tTcurrent_point=to_var(Tcurrent_point)\n\t\t\tTerror_all,Tout_norm_error,Tcross_error,Tline_to_obs_collision,Tpp_to_gt_error= Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,Tout_norm, Tout_orient_raw,Tbt1,Tbt2,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal) #1",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\t\tTmlp_in",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\t\tTmlp_in = torch.cat((Tzn,Tbi[:,28:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t\tTout_norm, Tout_orient_raw, Tout_orient_softm = mlp(Tmlp_in)   #([batch_size_test, 2])\n\t\t\t#Tout_angle=out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that considers all angle possibilities\n\t\t\tTout_angle=max_out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that take the most probable angle\n\t\t\tTpredict_point=angle_norm_to_coordinate(Tout_norm,Tout_angle,Tbi)\n\t\t\tTcurrent_point=to_var(Tcurrent_point)\n\t\t\tTerror_all,Tout_norm_error,Tcross_error,Tline_to_obs_collision,Tpp_to_gt_error= Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,Tout_norm, Tout_orient_raw,Tbt1,Tbt2,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal) #1\n\t\t\tTavg_error=Tavg_error+Terror_all.data #change by z\n\t\t\tTavg_out_norm_error=Tavg_out_norm_error+Tout_norm_error.data #change by z\n\t\t\tTavg_cross_error=Tavg_cross_error+Tcross_error.data #change by z",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tmlp",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tmlp = MLP(args.input_size,args.num_sector,args.dropout_p_MLP)\n\tencoder=AE.Encoder_CNN_2D(int(args.scale_para*40),args.dropout_p_CNN)\n\tif args.preload_all:\n\t\tmlp.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/MLP_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_mlp_model\")\n\t\tencoder.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/CNN_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_encoder_model\")\n\telif args.preload_encoder:\n\t\tencoder.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/Encoder_model/cae_encoder_cnn_2d_epoch_400_average loss_0.008726_Validation average loss_0.000000.pkl'))\n\t\tprint(\"just load_the_pre-trained_encoder_model\")",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\toptimizer",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\toptimizer = torch.optim.Adam([\n\t\t\t{'params': encoder.parameters(), 'lr': args.learning_rate_encoder},  # 为encoder设置的学习率\n\t\t\t{'params': mlp.parameters(), 'lr': args.learning_rate_planner}       # 为mlp设置的学习率\n\t\t])\n\telse:\n\t\toptimizer = torch.optim.Adam(list(encoder.parameters())+list(mlp.parameters()),lr=args.learning_rate_together) \n\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t\toptimizer",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t\toptimizer = torch.optim.Adam(list(encoder.parameters())+list(mlp.parameters()),lr=args.learning_rate_together) \n\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]\n\tUTtotal_error=[]\n\tsm=50 # start saving models after 100 epochs\n\tfor epoch in range(args.num_epochs):\n\t\tprint (\"epoch\" + str(epoch)+\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") #change by z\n\t\tavg_loss=0.0",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\t#optimizer",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]\n\tUTtotal_error=[]\n\tsm=50 # start saving models after 100 epochs\n\tfor epoch in range(args.num_epochs):\n\t\tprint (\"epoch\" + str(epoch)+\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") #change by z\n\t\tavg_loss=0.0\n\t\tavg_mse=0.0",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\tparser = argparse.ArgumentParser()\t\n\tparser.add_argument('--model_path', type=str, default='./models/crossentropy/test',help='path for saving trained models')\n\t# Model parameters\n\tparser.add_argument('--input_size', type=int , default=32, help='dimension of the input vector')\n\t# Mask map parameters\n\tparser.add_argument('--scale_para', type=float , default=4, help='the scale of mask map')\n\tparser.add_argument('--bias', type=float , default=20.0, help='the bias of mask map')\n#____________________________\n\t# the parameters under this line need to be adjust\n\tparser.add_argument('--num_epochs', type=int, default=4000)",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "ATOA.train_2D",
        "description": "ATOA.train_2D",
        "peekOfCode": "\targs = parser.parse_args()\n\tprint(args)\n\tmain(args)\n# it is for orientation version",
        "detail": "ATOA.train_2D",
        "documentation": {}
    },
    {
        "label": "check_data_valid",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def check_data_valid(data_list):\n\tfor data in data_list:\n\t\tif torch.isnan(data).any():\n\t\t\tprint(\"DISCOVER NAN!\")\n\t\t\tprint(data_list)\n\t\t\tassert 0\n\t\tif torch.isinf(data).any():\n\t\t\tprint(\"DISCOVER INF!\")\n\t\t\tprint(data_list)\n\t\t\tassert 0",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "to_var",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def to_var(x, volatile=False):\n\tif torch.cuda.is_available():\n\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "get_input",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]\n\t\tbt=targets[i:]\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)\ndef get_input_orient(i,env_indices,targets,padded_targets_future_all,data,\\\n\t\t     classification_orient_theta_targets,classification_orient_phi_targets\\",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "get_input_orient",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def get_input_orient(i,env_indices,targets,padded_targets_future_all,data,\\\n\t\t     classification_orient_theta_targets,classification_orient_phi_targets\\\n\t\t\t,classification_norm_targets,batch_size):\n\tif i+batch_size<len(data):\n\t\tbi=data[i:i+batch_size]\n\t\tbt1=classification_norm_targets[i:i+batch_size]\n\t\tbt2_theta=classification_orient_theta_targets[i:i+batch_size]\t\n\t\tbt2_phi=classification_orient_phi_targets[i:i+batch_size]\n\t\tcurrent_point=bi[:,60:63]\n\t\ttarget_point=targets[i:i+batch_size]\t",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "new_norm_loss",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播\ndef norm_loss_relu(x,distance_left):\n    epsilon = 1e-10\n    distance_left = torch.clamp(distance_left, min=epsilon)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "norm_loss_relu",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def norm_loss_relu(x,distance_left):\n    epsilon = 1e-10\n    distance_left = torch.clamp(distance_left, min=epsilon)\n    ratio = torch.clamp(x / distance_left,min=-5) - 1 #if x / distance_left too small, like -10, the exp(100) will become inf\n    scaled_ratio = -10 * ratio\n    return 0.5 * torch.log1p(torch.exp(scaled_ratio)) #log1p(x)=log(1+x)\ndef max_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm):\n\tmax_possibility_theta, max_index_theta = torch.max(out_orient_theta_softm, dim=-1)\n\tmax_possibility_phi, max_index_phi = torch.max(out_orient_phi_softm, dim=-1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "max_out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def max_out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm, out_orient_phi_softm):\n\tmax_possibility_theta, max_index_theta = torch.max(out_orient_theta_softm, dim=-1)\n\tmax_possibility_phi, max_index_phi = torch.max(out_orient_phi_softm, dim=-1)\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "out_softm_to_angle",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm,out_orient_phi_softm):\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "angle_norm_to_coordinate",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "f_DL2",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)\n# \tx = torch.unsqueeze(x, dim=0)\n# \tdistance_point_to_obstacle=torch.sqrt(torch.sum(torch.square(torch.sub(t,x)),dim=-1))\n# \tdistance_point_to_obstacle=f_DL(distance_point_to_obstacle,4)\n# \tdistance_point_to_obstacle=torch.sum(distance_point_to_obstacle,dim=0)\n# \tdistance_point_to_obstacle=torch.mean(distance_point_to_obstacle)\n# \treturn distance_point_to_obstacle",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Predict_point_to_GT_loss",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def Predict_point_to_GT_loss(targets_point_future_all_batch,predict_point):\n\tpredict_point_mid=torch.unsqueeze(predict_point, dim=1) #[batch,1,dimension]\n\tdistance_point_to_all_gt=torch.sqrt(torch.sum(torch.square(torch.sub(predict_point_mid,targets_point_future_all_batch)),dim=-1))#[batch,max_future_all_length]\n\tcheck_data_valid([distance_point_to_all_gt])\n\tdistance_point_to_gt,index_1=torch.min(distance_point_to_all_gt,dim=-1) #[batch]\n\tdistance_point_to_gt_mean=torch.mean(distance_point_to_gt)\n\t# assert 0\n\treturn distance_point_to_gt_mean\ndef Count_Distance_mid_points_loss(enviro_mask_set,boundary_points_set,boundary_lengths,predict_point,current_point,idx):  #it is for interpolation point and predicted point\n\t#!!!Please be aware not to use args.batch_size_train to create the dimensions of arrays, as errors may occur when the data is insufficient to fill args.batch_size_train.!!!",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Count_Distance_mid_points_loss",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def Count_Distance_mid_points_loss(enviro_mask_set,boundary_points_set,boundary_lengths,predict_point,current_point,idx):  #it is for interpolation point and predicted point\n\t#!!!Please be aware not to use args.batch_size_train to create the dimensions of arrays, as errors may occur when the data is insufficient to fill args.batch_size_train.!!!\n\t#idx:(batch_size_train); enviro_mask_set:(load_data_N,140,140);\tenviro_mask_set[idx]:(batch_size,140,140); \n \t#mask_total_point:[1,num,batch_size_train,2];boundary_points_set:(load_data_N,max_boundary_length,2)\n\tnum=args.interpolation_point_num #interpolation points: interpolation_point_num-1. when num=interpolation_point_num, it represent the predicted point\n\ttotal_point=torch.zeros((num,predict_point.shape[0],predict_point.shape[1]))\n\ttotal_point=total_point.cuda()\n\tfor i in range (0,num):\n\t\ttotal_point[i]=current_point+(predict_point-current_point)*(i+1)/num\n\ttotal_point = torch.unsqueeze(total_point, dim=0) #[1,num,batch_size,dimension]",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "loss_function",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def loss_function(enviro_mask_set,boundary_points_set,boundary_lengths,env_indices_batch,\\\n\t\t      out_norm,out_orient_theta_raw,out_orient_phi_raw,bt1,bt2_theta,bt2_phi,predict_point,current_point,targets_point_future_all_batch,distance_current_to_goal):\n\tk1=args.k1\n\tk2_theta=args.k2_theta\n\tk2_phi=args.k2_phi\n\tk3=args.k3\n\tk4=args.k4\n\tpp_to_gt_loss=Predict_point_to_GT_loss(targets_point_future_all_batch,predict_point)\n\t# print(\"current_point\")\n\t# print(current_point)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Error_function",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,Tout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,Tbt1,Tbt2_theta,Tbt2_phi,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal):\n\t# TDistance_point_loss=Count_Distance_loss(Tpredict_point,Tenv_indices_batch,Tobc)\n\tTline_to_obs_collision=Count_Distance_mid_points_loss(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tpredict_point,Tcurrent_point,Tenv_indices_batch)\n\t# Tk1=torch.tensor(1.0).cuda()\n\t# Tk2=torch.tensor(1.0).cuda()\n\t# Tk3=torch.tensor(0.001).cuda()\n\tTk1=args.Tk1\n\tTk2_theta=args.Tk2_theta\n\tTk2_phi=args.Tk2_phi\n\tTk3=args.Tk3",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "error_count",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def error_count(predict_point,target_point):\n\tPre_point_error=torch.square(torch.sub(predict_point,target_point))\n\tPre_point_error=torch.sqrt(torch.sum(Pre_point_error,dim=1)) \n\tPre_point_error=torch.mean(Pre_point_error)\n\treturn Pre_point_error\ndef Train(mlp,encoder,enviro_mask_set,boundary_points_set,boundary_lengths,env_indices,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets,optimizer,total_loss):\n\tencoder.train()\n\tmlp.train()\t\n\tloss = 0\n\t# print(\"args.batch_size_train\")",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Train",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def Train(mlp,encoder,enviro_mask_set,boundary_points_set,boundary_lengths,env_indices,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets,optimizer,total_loss):\n\tencoder.train()\n\tmlp.train()\t\n\tloss = 0\n\t# print(\"args.batch_size_train\")\n\t# print(args.batch_size_train)\n\tavg_loss=0\n\tavg_mse=0\n\tavg_cross_theta=0\n\tavg_cross_phi=0",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Test",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def Test(mlp,encoder,Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices,Ttargets,Tpadded_targets_future_all,Torient_dataset,Tclassification_orient_theta_targets,Tclassification_orient_phi_targets,Tclassification_norm_targets,Ttotal_error):\n\tmlp.eval()\n\tencoder.eval()\n\tTavg_error=0.0\n\tTavg_out_norm_error=0.0\n\tTavg_cross_error_theta=0.0\n\tTavg_cross_error_phi=0.0\n\tTavg_line_to_obs_collision=0.0\n\tTavg_Pre_point_error=0.0\n\tTavg_pp_to_gt_error=0",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "def main(args):\n\t# Create model directory\n\tif not os.path.exists(args.model_path):\n\t\tos.makedirs(args.model_path)\n\t# Build data loader\n\t#N=number of environments; NP=Number of Paths default:N=100,NP=4000\n\tenviro_mask_set,boundary_points_set,boundary_lengths,env_indices,dataset,targets,padded_targets_future_all,orient_dataset,classification_orient_theta_targets,classification_orient_phi_targets,classification_norm_targets\\\n\t\t= load_dataset_crossentropy(scale_para=args.scale_para,bias=args.bias,num_sector_theta=args.num_sector_theta,num_sector_phi=args.num_sector_phi,N=args.load_data_N,NP=args.load_data_NP,s=args.s,sp=args.sp) #type: numpy.ndarray N=10,NP=400\n\tprint(\"targets\",targets,targets.shape)\n\t# print(\"padded_targets_future_all\")",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\tx = x.cuda()\n\treturn Variable(x, volatile=volatile)\ndef get_input(i,data,targets,bs):\n\tif i+bs<len(data):\n\t\tbi=data[i:i+bs]\n\t\tbt=targets[i:i+bs]\t\n\telse:\n\t\tbi=data[i:]\n\t\tbt=targets[i:]\n\treturn torch.from_numpy(bi),torch.from_numpy(bt)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Cross_loss_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "Cross_loss_theta = nn.CrossEntropyLoss()\nCross_loss_phi = nn.CrossEntropyLoss()\nCross_loss_theta_test = nn.CrossEntropyLoss()\nCross_loss_phi_test = nn.CrossEntropyLoss()\ndef new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Cross_loss_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "Cross_loss_phi = nn.CrossEntropyLoss()\nCross_loss_theta_test = nn.CrossEntropyLoss()\nCross_loss_phi_test = nn.CrossEntropyLoss()\ndef new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Cross_loss_theta_test",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "Cross_loss_theta_test = nn.CrossEntropyLoss()\nCross_loss_phi_test = nn.CrossEntropyLoss()\ndef new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播\ndef norm_loss_relu(x,distance_left):",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "Cross_loss_phi_test",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "Cross_loss_phi_test = nn.CrossEntropyLoss()\ndef new_norm_loss(x, a, b, c):\n    sqrt_2 = torch.sqrt(torch.tensor(2.0)) \n    return  (a * torch.exp(-b * x) + c * torch.log(1 + torch.exp(x - 40 * sqrt_2)))\n# def norm_loss_relu(magnitude, target_magnitude=25, scale=0.1):\n#     loss = scale * (target_magnitude - magnitude)\n#     # return loss\n#     return torch.relu(loss)  # 使用PyTorch的ReLU以支持反向传播\ndef norm_loss_relu(x,distance_left):\n    epsilon = 1e-10",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n    # A model that take the most probable angle\n\tout_angle_max_theta=np.zeros((len(out_orient_theta_softm)),dtype=np.float32)\n\tout_angle_max_phi=np.zeros((len(out_orient_phi_softm)),dtype=np.float32)\n\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)\n\tfor i in range(0,len(out_angle_max_phi)):",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_max_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tout_angle_max_theta = torch.from_numpy(out_angle_max_theta).float().cuda()\n\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)\n\tfor i in range(0,len(out_angle_max_phi)):\n\t\tout_angle_max_phi[i]=center_angle_phi[max_index_phi[i]]\n\tout_angle_max_phi=out_angle_max_phi.unsqueeze(1)\n\treturn out_angle_max_theta,out_angle_max_phi\ndef out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm,out_orient_phi_softm):",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_max_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tout_angle_max_phi = torch.from_numpy(out_angle_max_phi).float().cuda()\n\tfor i in range(0,len(out_angle_max_theta)):\n\t\tout_angle_max_theta[i]=center_angle_theta[max_index_theta[i]]\n\tout_angle_max_theta=out_angle_max_theta.unsqueeze(1)\n\tfor i in range(0,len(out_angle_max_phi)):\n\t\tout_angle_max_phi[i]=center_angle_phi[max_index_phi[i]]\n\tout_angle_max_phi=out_angle_max_phi.unsqueeze(1)\n\treturn out_angle_max_theta,out_angle_max_phi\ndef out_softm_to_angle(num_sector_theta,num_sector_phi,out_orient_theta_softm,out_orient_phi_softm):\n\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_theta = np.linspace(0+180/num_sector_theta/2, 180-180/num_sector_theta/2, num_sector_theta) #center_angle for each sector\n\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_theta = torch.from_numpy(center_angle_theta).float().cuda()\n\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_theta = center_angle_theta.unsqueeze(0) #cuda\n\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_phi = np.linspace(-180+360/num_sector_phi/2, 180-360/num_sector_phi/2, num_sector_phi) #center_angle for each sector\n\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_phi = torch.from_numpy(center_angle_phi).float().cuda()\n\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tcenter_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tcenter_angle_phi = center_angle_phi.unsqueeze(0) #cuda\n\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tout_angle_theta = torch.mul(center_angle_theta, out_orient_theta_softm) # (batch_size,num_sector)\n\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tout_angle_phi = torch.mul(center_angle_phi, out_orient_phi_softm) # (batch_size,num_sector)\n\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_theta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tout_angle_theta = torch.sum(out_angle_theta, dim=-1) # (batch_size,)\n\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tout_angle_phi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tout_angle_phi = torch.sum(out_angle_phi, dim=-1) # (batch_size,)\n\tout_angle_theta=out_angle_theta.unsqueeze(1) #add a dimension\n\tout_angle_phi=out_angle_phi.unsqueeze(1) #add a dimension\n\treturn out_angle_theta,out_angle_phi\ndef angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi):\n\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\ttheta",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\ttheta = out_angle_theta / 360 * 2 * math.pi\n\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tphi",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tphi = out_angle_phi / 360 * 2 * math.pi\n\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tx",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tx = bi[:, 60].unsqueeze(1) + torch.sin(theta) * torch.cos(phi) * out_norm\n\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) ",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\ty",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\ty = bi[:, 61].unsqueeze(1) + torch.sin(theta) * torch.sin(phi) * out_norm\n\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tz",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tz = bi[:, 62].unsqueeze(1) + torch.cos(theta) * out_norm\n\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tpredict_point",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tpredict_point = torch.cat((x, y, z), dim=1)\n\treturn predict_point\n# def f_DL(x, k):\n# \t#return np.exp(-k*(x-3.53553390)) #circumscribed circle\n#     return torch.exp(-k*(x-2.5)) #inscribed circle\ndef f_DL2(x, k):\n\treturn torch.exp(-k*(x)) \n# def Count_Distance_loss(x,idx,obc):  #it is for predict point\n# \tt=obc[idx].transpose(1,0)\n# \tx = torch.unsqueeze(x, dim=0)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\ttotal_point",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\ttotal_point = torch.unsqueeze(total_point, dim=0) #[1,num,batch_size,dimension]\n\tcheck_data_valid([total_point])\n\tboundary_points=boundary_points_set[idx] #(batch_size,max_boundary_length,dimension)\n\tboundary_points=to_var(boundary_points)\n\tboundary_points=boundary_points.transpose(1,0) #(max_boundary_length,batch_size,dimension)\n\tboundary_points=torch.unsqueeze(boundary_points, dim=1) #(max_boundary_length,1,batch_size,dimension)\n\tcheck_data_valid([boundary_points])\n\tmask_total_point=torch.add(total_point,args.bias)*args.scale_para #mask_total_point:[1,num,batch_size_train,dimension] [1,5,6,3]\n\tcheck_data_valid([mask_total_point])\n\tmask_total_point_floor=torch.floor(mask_total_point).to(torch.long) #[1,num,batch_size_train,dimension]",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tsign_value",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tsign_value = 1 - 2 * sign_value\n\tcheck_data_valid([sign_value])\n\tsign_value=sign_value.transpose(0,1) #sign_value(num,batch_size)\n\t#boundary_points(max_boundary_length,1,batch_size,2) total_point[1,num,batch_size,2] #sign_value(num,batch_size)\n\tdistance_point_to_boundary_points=torch.sqrt(torch.sum(torch.square(torch.sub(boundary_points,total_point)),dim=-1)) #(max_boundary_length,num,batch_size)\n\tcheck_data_valid([distance_point_to_boundary_points])\n\tdistance_point_to_obstacle,to_obstacle_index=torch.min(distance_point_to_boundary_points,dim=0) #(num,batch_size)\n\t# print(\"distance_point_to_obstacle\")\n\t# print(distance_point_to_obstacle)\n\tcheck_data_valid([distance_point_to_obstacle])",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tloss",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tloss = 0\n\t# print(\"args.batch_size_train\")\n\t# print(args.batch_size_train)\n\tavg_loss=0\n\tavg_mse=0\n\tavg_cross_theta=0\n\tavg_cross_phi=0\n\tavg_point_error=0\n\tavg_line_to_obs_loss=0\n\tavg_pp_to_gt_loss=0",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\tbt1",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\tbt1 = torch.unsqueeze(bt1, dim=1) #from [batch_size] to [batch_size,1]\n\t\tbt2_theta=to_var(bt2_theta)\n\t\tbt2_phi=to_var(bt2_phi)\n\t\t# print(\"enviro_mask_set[env_indices_batch].unsqueeze(1)\",enviro_mask_set[env_indices_batch].unsqueeze(1).shape)\n\t\tzn=encoder(enviro_mask_set[env_indices_batch].unsqueeze(1))\n\t\t# print(\"zn\",zn.shape)\n\t\tmlp_in = torch.cat((zn,bi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\tout_norm, out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t\t  out_orient_theta_softm, out_orient_phi_softm= mlp(mlp_in)   #torch.Tensor+cuda\n\t\t# print(\"out_norm\",out_norm,out_norm.shape)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\tmlp_in",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\tmlp_in = torch.cat((zn,bi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\tout_norm, out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t\t  out_orient_theta_softm, out_orient_phi_softm= mlp(mlp_in)   #torch.Tensor+cuda\n\t\t# print(\"out_norm\",out_norm,out_norm.shape)\n\t\tcheck_data_valid([out_norm,out_orient_theta_raw,out_orient_phi_raw,\\\n\t\t    out_orient_theta_softm,out_orient_phi_softm])\n\t\tout_angle_theta,out_angle_phi=out_softm_to_angle(args.num_sector_theta,args.num_sector_phi,out_orient_theta_softm,out_orient_phi_softm)\n\t\tpredict_point=angle_norm_to_coordinate(out_norm,out_angle_theta,out_angle_phi,bi) #cuda\n\t\tcurrent_point=to_var(current_point)\n\t\tcheck_data_valid([out_angle_theta,out_angle_phi,predict_point,current_point])",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\tloss_all,out_norm_loss,loss_cross_theta,loss_cross_phi,line_to_obs_loss,pp_to_gt_loss",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\tloss_all,out_norm_loss,loss_cross_theta,loss_cross_phi,line_to_obs_loss,pp_to_gt_loss = loss_function(enviro_mask_set,boundary_points_set,boundary_lengths,env_indices_batch,\\\n\t\t\t\t\t\t\t   out_norm,out_orient_theta_raw,out_orient_phi_raw,bt1,bt2_theta,bt2_phi,predict_point,current_point,targets_point_future_all_batch,distance_current_to_goal) #1\n\t\tloss_all.backward()\n\t\toptimizer.step()\n\t\tpredict_point_cpu=predict_point.cpu()\n\t\tPre_point_error=error_count(predict_point_cpu,target_point)\n\t\tavg_loss=avg_loss+loss_all.data #change by z\n\t\tavg_out_norm_loss=avg_out_norm_loss+out_norm_loss.data #change by z\n\t\tavg_cross_theta=avg_cross_theta+loss_cross_theta.data #change by z\n\t\tavg_cross_phi=avg_cross_phi+loss_cross_phi.data #change by z",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\t\tTbt1",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\t\tTbt1 = torch.unsqueeze(Tbt1, dim=1) #from [batch_size_test] to [batch_size_test,1]\n\t\t\tTbt2_theta=to_var(Tbt2_theta)\n\t\t\tTbt2_phi=to_var(Tbt2_phi)\n\t\t\tTzn=encoder(Tenviro_mask_set[Tenv_indices_batch].unsqueeze(1))\n\t\t\tTmlp_in = torch.cat((Tzn,Tbi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t\tTout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,\\\n\t\t\t  Tout_orient_theta_softm, Tout_orient_phi_softm= mlp(Tmlp_in)   #torch.Tensor+cuda\n\t\t\t# Tout_angle=out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that considers all angle possibilities\n\t\t\tTout_angle_theta,Tout_angle_phi=max_out_softm_to_angle(args.num_sector_theta,args.num_sector_phi,Tout_orient_theta_softm, Tout_orient_phi_softm) # A model that take the most probable angle\n\t\t\tTpredict_point=angle_norm_to_coordinate(Tout_norm,Tout_angle_theta,Tout_angle_phi,Tbi) #cuda",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\t\tTmlp_in",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\t\tTmlp_in = torch.cat((Tzn,Tbi[:,60:]), 1)    # keep the first dim the same (# samples) [path_length-1,32]\n\t\t\tTout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,\\\n\t\t\t  Tout_orient_theta_softm, Tout_orient_phi_softm= mlp(Tmlp_in)   #torch.Tensor+cuda\n\t\t\t# Tout_angle=out_softm_to_angle(args.num_sector,Tout_orient_softm) # A model that considers all angle possibilities\n\t\t\tTout_angle_theta,Tout_angle_phi=max_out_softm_to_angle(args.num_sector_theta,args.num_sector_phi,Tout_orient_theta_softm, Tout_orient_phi_softm) # A model that take the most probable angle\n\t\t\tTpredict_point=angle_norm_to_coordinate(Tout_norm,Tout_angle_theta,Tout_angle_phi,Tbi) #cuda\n\t\t\tTcurrent_point=to_var(Tcurrent_point)\n\t\t\tTerror_all,Tout_norm_error,Tcross_error_theta,Tcross_error_phi,Tline_to_obs_collision,Tpp_to_gt_error= Error_function(Tenviro_mask_set,Tboundary_points_set,Tboundary_lengths,Tenv_indices_batch,Tout_norm, Tout_orient_theta_raw,Tout_orient_phi_raw,Tbt1,Tbt2_theta,Tbt2_phi,Tpredict_point,Tcurrent_point,Ttargets_point_future_all_batch,Tdistance_current_to_goal) #1\n\t\t\tTavg_error=Tavg_error+Terror_all.data #change by z\n\t\t\tTavg_out_norm_error=Tavg_out_norm_error+Tout_norm_error.data #change by z",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tmlp",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tmlp = MLP_3D(args.input_size,args.num_sector_theta,args.num_sector_phi,args.dropout_p_MLP)\n\tencoder=AE.Encoder_CNN_3D(int(args.scale_para*40),args.dropout_p_CNN)\n\tif args.preload_all:\n\t\tmlp.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/MLP_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_mlp_model\")\n\t\tencoder.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/CNN_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_encoder_model\")\n\telif args.preload_encoder:\n\t\tencoder.load_state_dict(torch.load('models/crossentropy/test/CNN_NEWLOSS/CNN_E2E_cross_mask_concave2d_epoch=4_N_10_Np_400_avg_loss=16.299_avg_out_norm_loss=0.416_avg_cross=14.632_avg_line_to_obs_loss=0.159_avg_pp_to_gt_loss=1.092_avg_point_error=10.279.pkl'))\n\t\tprint(\"load_the_pre-trained_encoder_model\")",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\toptimizer",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\toptimizer = torch.optim.Adam([\n\t\t\t{'params': encoder.parameters(), 'lr': args.learning_rate_encoder},  # 为encoder设置的学习率\n\t\t\t{'params': mlp.parameters(), 'lr': args.learning_rate_planner}       # 为mlp设置的学习率\n\t\t])\n\telse:\n\t\toptimizer = torch.optim.Adam(list(encoder.parameters())+list(mlp.parameters()),lr=args.learning_rate_together) \n\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t\toptimizer",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t\toptimizer = torch.optim.Adam(list(encoder.parameters())+list(mlp.parameters()),lr=args.learning_rate_together) \n\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]\n\tUTtotal_error=[]\n\tsm=50 # start saving models after 100 epochs\n\tfor epoch in range(args.num_epochs):\n\t\tprint (\"epoch\" + str(epoch)+\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") #change by z\n\t\tavg_loss=0.0",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\t#optimizer",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\t#optimizer = torch.optim.Adagrad(mlp.parameters()) \n\t# Train the Models\n\ttotal_loss=[]\n\tTtotal_error=[]\n\tUTtotal_error=[]\n\tsm=50 # start saving models after 100 epochs\n\tfor epoch in range(args.num_epochs):\n\t\tprint (\"epoch\" + str(epoch)+\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\") #change by z\n\t\tavg_loss=0.0\n\t\tavg_mse=0.0",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\tparser",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\tparser = argparse.ArgumentParser()\t\n\tparser.add_argument('--model_path', type=str, default='./models/crossentropy/test',help='path for saving trained models')\n\t# Model parameters\n\tparser.add_argument('--input_size', type=int , default=32, help='dimension of the input vector')\n\t# Mask map parameters\n\tparser.add_argument('--scale_para', type=float , default=4, help='the scale of mask map')\n\tparser.add_argument('--bias', type=float , default=20.0, help='the bias of mask map')\n#____________________________\n\t# the parameters under this line need to be adjust\n\tparser.add_argument('--num_epochs', type=int, default=4000)",
        "detail": "ATOA.train_3D",
        "documentation": {}
    },
    {
        "label": "\targs",
        "kind": 5,
        "importPath": "ATOA.train_3D",
        "description": "ATOA.train_3D",
        "peekOfCode": "\targs = parser.parse_args()\n\tprint(args)\n\tmain(args)\n# it is for orientation version",
        "detail": "ATOA.train_3D",
        "documentation": {}
    }
]